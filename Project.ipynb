{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment and indicator calculation"
      ],
      "metadata": {
        "id": "anK2XVYMHwmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice for Reviewing This Notebook\n",
        "This notebook contains Step 1–5 results for both datasets (Adult & Kaggle).\n",
        "Due to the large memory requirements in Step 5, please do not click “Run all”.\n",
        "Instead:\n",
        "\n",
        "All results have already been executed and displayed in the output cells.\n",
        "\n",
        "Scroll down to see the printed tables (raw results, mean±std summaries, significance tests).\n",
        "\n",
        "\n",
        "If re-running is necessary, we recommend executing Step 5A (Adult) and Step 5B (Kaggle) separately to avoid RAM overflow."
      ],
      "metadata": {
        "id": "o4cLNqP4PXGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcQhgvEkEtd",
        "outputId": "640a2b69-85ed-4c02-e214-615b6afa5339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/259.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/259.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tensorstore 0.1.76 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.15.0 which is incompatible.\n",
            "keras-hub 0.21.1 requires keras>=3.5, but you have keras 2.15.0 which is incompatible.\n",
            "jax 0.5.3 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install aif360==0.6.1 folktables==0.0.12 imbalanced-learn==0.12.3\n",
        "!pip -q install scikit-learn==1.4.2 pandas==2.2.2 numpy==1.26.4 scipy==1.13.1\n",
        "!pip -q install tensorflow==2.15.0\n",
        "!pip -q install \"aif360[Reductions]\" \"aif360[inFairness]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, signal, sys, time\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n"
      ],
      "metadata": {
        "id": "TmIUI0GJG7nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, random\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset, AdultDataset\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED); random.seed(SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQU_ntqnFPwC",
        "outputId": "4a8d218c-9d28-4780-c011-50f6fab6496d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  vect_normalized_discounted_cumulative_gain = vmap(\n",
            "/usr/local/lib/python3.11/dist-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "60RyE6NzI_Ha",
        "outputId": "4e792691-fa6b-459f-f1de-923050ab0a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b22725e-86f6-4944-8041-01bd8881f4be\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b22725e-86f6-4944-8041-01bd8881f4be\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving recruitment_data.csv to recruitment_data (1).csv\n",
            "Saving adult_test.csv to adult_test (1).csv\n",
            "Saving adult_train.csv to adult_train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"adult_train.csv\")\n",
        "test_df = pd.read_csv(\"adult_test.csv\")\n",
        "kaggle_df = pd.read_csv(\"recruitment_data.csv\")\n",
        "\n",
        "print(\"Training set size:\", train_df.shape)\n",
        "print(\"Test set size:\", test_df.shape)\n",
        "print(\"Kaggle set size:\", kaggle_df.shape)\n",
        "\n",
        "# Step 1: Data inspection and light normalization\n",
        "\n",
        "# 1.1 Basic overview\n",
        "print('\\n[Columns] train:', train_df.columns.tolist())\n",
        "print('[Columns] test :', test_df.columns.tolist())\n",
        "print('[Columns] kaggle:', kaggle_df.columns.tolist())\n",
        "\n",
        "print('\\n[Head] Adult train:')\n",
        "display(train_df.head(3))\n",
        "print('\\n[Head] Adult test:')\n",
        "display(test_df.head(3))\n",
        "print('\\n[Head] Kaggle:')\n",
        "display(kaggle_df.head(3))\n",
        "\n",
        "# 1.2 Quick statistics & label distribution\n",
        "for name, df in [('Adult train', train_df), ('Adult test', test_df)]:\n",
        "    if 'income' in df.columns:\n",
        "        print(f'\\n[{name}] income value_counts:')\n",
        "        print(df['income'].value_counts(dropna=False))\n",
        "    else:\n",
        "        print(f'\\n[{name}] No income column found, please confirm label column name')\n",
        "\n",
        "# 1.3 Remove leading/trailing spaces in string columns\n",
        "def strip_object_cols(df):\n",
        "    out = df.copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == object:\n",
        "            out[c] = out[c].astype(str).str.strip()\n",
        "    return out\n",
        "\n",
        "train_df = strip_object_cols(train_df)\n",
        "test_df  = strip_object_cols(test_df)\n",
        "kaggle_df = strip_object_cols(kaggle_df)\n",
        "\n",
        "# 1.4 Replace '?' and empty strings with NaN for consistent missing value handling\n",
        "replace_map = {'?': np.nan, '': np.nan, ' ': np.nan}\n",
        "train_df = train_df.replace(replace_map)\n",
        "test_df  = test_df.replace(replace_map)\n",
        "kaggle_df = kaggle_df.replace(replace_map)\n",
        "\n",
        "# 1.5 Re-check income distribution in test set\n",
        "print('\\n[After strip/replace] Adult test income value_counts:')\n",
        "if 'income' in test_df.columns:\n",
        "    print(test_df['income'].value_counts(dropna=False))\n",
        "else:\n",
        "    print('No income column found in Adult test set')\n",
        "\n",
        "print('Step 1 complete.')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q-KiK1beKStB",
        "outputId": "6dbf2411-afdb-4905-954a-0ed3f7f7e74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (32561, 15)\n",
            "Test set size: (16280, 15)\n",
            "Kaggle set size: (1500, 11)\n",
            "\n",
            "[Columns] train: ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
            "[Columns] test : ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
            "[Columns] kaggle: ['Age', 'Gender', 'EducationLevel', 'ExperienceYears', 'PreviousCompanies', 'DistanceFromCompany', 'InterviewScore', 'SkillScore', 'PersonalityScore', 'RecruitmentStrategy', 'HiringDecision']\n",
            "\n",
            "[Head] Adult train:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   age         workclass  fnlwgt  education  education-num  \\\n",
              "0   39         State-gov   77516  Bachelors             13   \n",
              "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
              "2   38           Private  215646    HS-grad              9   \n",
              "\n",
              "       marital-status         occupation   relationship   race   sex  \\\n",
              "0       Never-married       Adm-clerical  Not-in-family  White  Male   \n",
              "1  Married-civ-spouse    Exec-managerial        Husband  White  Male   \n",
              "2            Divorced  Handlers-cleaners  Not-in-family  White  Male   \n",
              "\n",
              "   capital-gain  capital-loss  hours-per-week native-country income  \n",
              "0          2174             0              40  United-States  <=50K  \n",
              "1             0             0              13  United-States  <=50K  \n",
              "2             0             0              40  United-States  <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54a2209d-edbe-4433-8159-53e41863a9a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54a2209d-edbe-4433-8159-53e41863a9a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54a2209d-edbe-4433-8159-53e41863a9a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54a2209d-edbe-4433-8159-53e41863a9a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ec834356-f5c8-438f-b29f-68e4c80ce2f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec834356-f5c8-438f-b29f-68e4c80ce2f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ec834356-f5c8-438f-b29f-68e4c80ce2f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print('Step 1 complete\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 38,\n        \"max\": 50,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          39,\n          50,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"State-gov\",\n          \"Self-emp-not-inc\",\n          \"Private\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78130,\n        \"min\": 77516,\n        \"max\": 215646,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          77516,\n          83311,\n          215646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"HS-grad\",\n          \"Bachelors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 9,\n        \"max\": 13,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Never-married\",\n          \"Married-civ-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Adm-clerical\",\n          \"Exec-managerial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Husband\",\n          \"Not-in-family\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"White\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1255,\n        \"min\": 0,\n        \"max\": 2174,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 13,\n        \"max\": 40,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"United-States\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Head] Adult test:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
              "0   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
              "1   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
              "2   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
              "\n",
              "          occupation relationship   race   sex  capital-gain  capital-loss  \\\n",
              "0    Farming-fishing      Husband  White  Male             0             0   \n",
              "1    Protective-serv      Husband  White  Male             0             0   \n",
              "2  Machine-op-inspct      Husband  Black  Male          7688             0   \n",
              "\n",
              "   hours-per-week native-country income  \n",
              "0              50  United-States  <=50K  \n",
              "1              40  United-States   >50K  \n",
              "2              40  United-States   >50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82ff4c37-8f5d-4be8-adde-d2f279e7dc78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82ff4c37-8f5d-4be8-adde-d2f279e7dc78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82ff4c37-8f5d-4be8-adde-d2f279e7dc78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82ff4c37-8f5d-4be8-adde-d2f279e7dc78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d356bc2d-0024-4a70-b9d5-20e900c5a596\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d356bc2d-0024-4a70-b9d5-20e900c5a596')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d356bc2d-0024-4a70-b9d5-20e900c5a596 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print('Step 1 complete\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 28,\n        \"max\": 44,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          38,\n          28,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Local-gov\",\n          \"Private\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 127309,\n        \"min\": 89814,\n        \"max\": 336951,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          89814,\n          336951\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HS-grad\",\n          \"Assoc-acdm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 9,\n        \"max\": 12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Married-civ-spouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Farming-fishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Husband\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Black\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4438,\n        \"min\": 0,\n        \"max\": 7688,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7688\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 40,\n        \"max\": 50,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"United-States\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Head] Kaggle:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Age  Gender  EducationLevel  ExperienceYears  PreviousCompanies  \\\n",
              "0   26       1               2                0                  3   \n",
              "1   39       1               4               12                  3   \n",
              "2   48       0               2                3                  2   \n",
              "\n",
              "   DistanceFromCompany  InterviewScore  SkillScore  PersonalityScore  \\\n",
              "0            26.783828              48          78                91   \n",
              "1            25.862694              35          68                80   \n",
              "2             9.920805              20          67                13   \n",
              "\n",
              "   RecruitmentStrategy  HiringDecision  \n",
              "0                    1               1  \n",
              "1                    2               1  \n",
              "2                    2               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f64f6fc4-2991-45a6-a3dd-4f0a6ad260a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>EducationLevel</th>\n",
              "      <th>ExperienceYears</th>\n",
              "      <th>PreviousCompanies</th>\n",
              "      <th>DistanceFromCompany</th>\n",
              "      <th>InterviewScore</th>\n",
              "      <th>SkillScore</th>\n",
              "      <th>PersonalityScore</th>\n",
              "      <th>RecruitmentStrategy</th>\n",
              "      <th>HiringDecision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>26.783828</td>\n",
              "      <td>48</td>\n",
              "      <td>78</td>\n",
              "      <td>91</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>25.862694</td>\n",
              "      <td>35</td>\n",
              "      <td>68</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9.920805</td>\n",
              "      <td>20</td>\n",
              "      <td>67</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f64f6fc4-2991-45a6-a3dd-4f0a6ad260a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f64f6fc4-2991-45a6-a3dd-4f0a6ad260a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f64f6fc4-2991-45a6-a3dd-4f0a6ad260a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6852115f-54ae-4364-ac0b-937f9c7932ab\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6852115f-54ae-4364-ac0b-937f9c7932ab')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6852115f-54ae-4364-ac0b-937f9c7932ab button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print('Step 1 complete\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 26,\n        \"max\": 48,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          26,\n          39,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EducationLevel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ExperienceYears\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreviousCompanies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DistanceFromCompany\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.481155544355268,\n        \"min\": 9.920804828174788,\n        \"max\": 26.78382755385365,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          26.78382755385365,\n          25.8626943295439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"InterviewScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 20,\n        \"max\": 48,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          48,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkillScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 67,\n        \"max\": 78,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          78,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PersonalityScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 13,\n        \"max\": 91,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          91,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RecruitmentStrategy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HiringDecision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Adult train] income value_counts:\n",
            "income\n",
            "<=50K    24720\n",
            ">50K      7841\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[Adult test] income value_counts:\n",
            "income\n",
            "<=50K    12434\n",
            ">50K      3846\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[After strip/replace] Adult test income value_counts:\n",
            "income\n",
            "<=50K    12434\n",
            ">50K      3846\n",
            "Name: count, dtype: int64\n",
            "Step 1 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Full cleaning & leakage prevention\n",
        "\n",
        "\n",
        "# 2.1 Helpers\n",
        "\n",
        "def strip_object_cols(df):\n",
        "    out = df.copy()\n",
        "    for c in out.columns:\n",
        "        if out[c].dtype == object:\n",
        "            out[c] = out[c].astype(str).str.strip()\n",
        "    return out\n",
        "\n",
        "\n",
        "def clean_adult_df(df: pd.DataFrame,\n",
        "                   label_col: str = 'income',\n",
        "                   age_thr: int = 40,\n",
        "                   edu_thr: int = 13) -> pd.DataFrame:\n",
        "    \"\"\"Standardize Adult: strip spaces, unify label to 0/1, mark NaNs, cast numeric,\n",
        "       and derive sensitive attributes: age_bin, edu_bin.\"\"\"\n",
        "    out = strip_object_cols(df)\n",
        "\n",
        "    # Replace common missing markers with NaN\n",
        "    out = out.replace({'?': np.nan, '': np.nan, ' ': np.nan})\n",
        "\n",
        "    # Label -> numeric {<=50K:0, >50K:1} (support dotted variants if present)\n",
        "    if label_col not in out.columns:\n",
        "        raise ValueError(f\"Label column '{label_col}' not found in Adult dataset.\")\n",
        "    if out[label_col].dtype == object:\n",
        "        lab_map = {'>50K':1, '<=50K':0, '>50K.':1, '<=50K.':0}\n",
        "        out['label'] = out[label_col].map(lab_map).astype('Int64')\n",
        "    else:\n",
        "        out['label'] = out[label_col].astype(int)\n",
        "\n",
        "    # Cast likely numeric columns\n",
        "    for c in ['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']:\n",
        "        if c in out.columns:\n",
        "            out[c] = pd.to_numeric(out[c], errors='coerce')\n",
        "\n",
        "    # Derive sensitive attributes (for fairness eval & debiasing constraints, not for model input)\n",
        "    out['age_bin'] = (out['age'] < age_thr).astype('Int64') if 'age' in out.columns else pd.Series([pd.NA]*len(out), dtype='Int64')\n",
        "    if 'education-num' in out.columns:\n",
        "        out['edu_bin'] = (pd.to_numeric(out['education-num'], errors='coerce') < edu_thr).astype('Int64')\n",
        "    else:\n",
        "        out['edu_bin'] = pd.Series([pd.NA]*len(out), dtype='Int64')\n",
        "\n",
        "    return out\n",
        "\n",
        "def clean_kaggle_df(df: pd.DataFrame,\n",
        "                    label_col: str = 'HiringDecision',\n",
        "                    age_col: str = 'Age',\n",
        "                    edu_col: str = 'EducationLevel',\n",
        "                    age_thr: int = 40,\n",
        "                    edu_low_max: int = 2) -> pd.DataFrame:\n",
        "    \"\"\"Standardize Kaggle recruitment: strip spaces, unify label to 0/1,\n",
        "       cast numeric, map ordered education, and derive sensitive bins.\"\"\"\n",
        "    out = strip_object_cols(df)\n",
        "    out = out.replace({'?': np.nan, '': np.nan, ' ': np.nan})\n",
        "\n",
        "    # Label -> numeric 0/1\n",
        "    if label_col not in out.columns:\n",
        "        raise ValueError(f\"Label column '{label_col}' not found in Kaggle dataset.\")\n",
        "    out['label'] = pd.to_numeric(out[label_col], errors='coerce').astype('Int64')\n",
        "\n",
        "    # Cast likely numeric columns (extend if your CSV has more)\n",
        "    numeric_like = ['Age','ExperienceYears','PreviousCompanies','DistanceFromCompany',\n",
        "                    'InterviewScore','SkillScore','PersonalityScore']\n",
        "    for c in numeric_like:\n",
        "        if c in out.columns:\n",
        "            out[c] = pd.to_numeric(out[c], errors='coerce')\n",
        "\n",
        "    # Map ordered education if it's categorical\n",
        "    if edu_col in out.columns:\n",
        "        if out[edu_col].dtype == object:\n",
        "            edu_map = {'HighSchool':1, 'Diploma':2, 'Bachelors':3, 'Masters':4, 'PhD':5}\n",
        "            out['education_ord'] = out[edu_col].map(edu_map).astype('Int64')\n",
        "        else:\n",
        "            out['education_ord'] = pd.to_numeric(out[edu_col], errors='coerce').astype('Int64')\n",
        "    else:\n",
        "        out['education_ord'] = pd.Series([pd.NA]*len(out), dtype='Int64')\n",
        "\n",
        "    # Sensitive attributes\n",
        "    if age_col in out.columns:\n",
        "        out['age_bin'] = (pd.to_numeric(out[age_col], errors='coerce') < age_thr).astype('Int64')\n",
        "    else:\n",
        "        out['age_bin'] = pd.Series([pd.NA]*len(out), dtype='Int64')\n",
        "\n",
        "    # Low education protected group (<= Diploma)\n",
        "    out['edu_bin'] = (out['education_ord'] <= edu_low_max).astype('Int64')\n",
        "\n",
        "    return out\n",
        "\n",
        "def detect_leak_columns(df: pd.DataFrame,\n",
        "                        label: str = 'label',\n",
        "                        base_drop: list = None,\n",
        "                        max_unique: int = 10,\n",
        "                        corr_thresh: float = 0.999) -> list:\n",
        "    \"\"\"Detect suspicious leak features: near-perfect correlation with label (numeric)\n",
        "       or perfect separation (categorical with small cardinality).\"\"\"\n",
        "    if base_drop is None:\n",
        "        base_drop = []\n",
        "    leak_cols = set()\n",
        "    y = pd.to_numeric(df[label], errors='coerce').astype(float)\n",
        "\n",
        "    for c in df.columns:\n",
        "        if c in base_drop or c == label:\n",
        "            continue\n",
        "        s = df[c]\n",
        "        # Numeric correlation near ±1\n",
        "        if s.dtype.kind in 'ifu':\n",
        "            s = pd.to_numeric(s, errors='coerce')\n",
        "            corr = s.corr(y)\n",
        "            if pd.notna(corr) and abs(corr) >= corr_thresh:\n",
        "                leak_cols.add(c)\n",
        "        else:\n",
        "            # Categorical perfect partition: each category maps to a single label\n",
        "            nunique = s.nunique(dropna=True)\n",
        "            if nunique <= max_unique and nunique > 0:\n",
        "                tab = df[[c, label]].dropna().groupby(c)[label].nunique()\n",
        "                if len(tab) > 0 and (tab <= 1).all():\n",
        "                    leak_cols.add(c)\n",
        "    return sorted(list(leak_cols))\n",
        "\n",
        "def check_train_test_overlap(train_df: pd.DataFrame, test_df: pd.DataFrame) -> int:\n",
        "    \"\"\"Rough overlap check by hashing rows (after sorting columns).\"\"\"\n",
        "    common_cols = sorted(set(train_df.columns) & set(test_df.columns))\n",
        "    if not common_cols:\n",
        "        return 0\n",
        "    t_hash = pd.util.hash_pandas_object(train_df[common_cols], index=False)\n",
        "    e_hash = pd.util.hash_pandas_object(test_df[common_cols], index=False)\n",
        "    overlap = np.intersect1d(t_hash.values, e_hash.values).size\n",
        "    return int(overlap)\n",
        "\n",
        "# 2.2 Clean datasets\n",
        "\n",
        "# Adult\n",
        "train_df = clean_adult_df(train_df, label_col='income', age_thr=40, edu_thr=13)\n",
        "test_df  = clean_adult_df(test_df,  label_col='income', age_thr=40, edu_thr=13)\n",
        "\n",
        "# Kaggle\n",
        "kaggle_df = clean_kaggle_df(kaggle_df,\n",
        "                            label_col='HiringDecision',\n",
        "                            age_col='Age',\n",
        "                            edu_col='EducationLevel',\n",
        "                            age_thr=40,\n",
        "                            edu_low_max=2)\n",
        "\n",
        "# 2.3 Leakage prevention setup\n",
        "\n",
        "adult_base_drop = ['label', 'age_bin', 'edu_bin', 'income']\n",
        "kaggle_base_drop = ['label', 'age_bin', 'edu_bin', 'education_ord', 'HiringDecision']\n",
        "\n",
        "# Detect suspicious leak columns\n",
        "adult_leaks = detect_leak_columns(train_df, label='label', base_drop=adult_base_drop)\n",
        "kaggle_leaks = detect_leak_columns(kaggle_df, label='label', base_drop=kaggle_base_drop)\n",
        "\n",
        "print('Adult suspicious leak columns:', adult_leaks if adult_leaks else 'None')\n",
        "print('Kaggle suspicious leak columns:', kaggle_leaks if kaggle_leaks else 'None')\n",
        "\n",
        "# 2.4 Train/Test overlap check for Adult\n",
        "overlap_n = check_train_test_overlap(train_df, test_df)\n",
        "print(f'Adult train/test potential row overlap (hash-based): {overlap_n}')\n",
        "\n",
        "# 2.5 Quick QC summaries\n",
        "\n",
        "def qc_summary(name: str, df: pd.DataFrame, label_col='label'):\n",
        "    print(f'\\n--- {name} QC ---')\n",
        "    if label_col in df.columns:\n",
        "        print('Label distribution:')\n",
        "        print(df[label_col].value_counts(dropna=False))\n",
        "    misses = df.isna().sum().sort_values(ascending=False).head(10)\n",
        "    print('\\nTop-10 columns by missing values:')\n",
        "    print(misses)\n",
        "\n",
        "qc_summary('Adult TRAIN', train_df)\n",
        "qc_summary('Adult TEST', test_df)\n",
        "qc_summary('Kaggle (raw, before split)', kaggle_df)\n",
        "\n",
        "print('Step 2 done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8-WoEsDp2CT",
        "outputId": "c456dcd1-fc03-45fe-bc1e-ccba89551f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adult suspicious leak columns: None\n",
            "Kaggle suspicious leak columns: None\n",
            "Adult train/test potential row overlap (hash-based): 23\n",
            "\n",
            "--- Adult TRAIN QC ---\n",
            "Label distribution:\n",
            "label\n",
            "0    24720\n",
            "1     7841\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "Top-10 columns by missing values:\n",
            "age               0\n",
            "workclass         0\n",
            "age_bin           0\n",
            "label             0\n",
            "income            0\n",
            "native-country    0\n",
            "hours-per-week    0\n",
            "capital-loss      0\n",
            "capital-gain      0\n",
            "sex               0\n",
            "dtype: int64\n",
            "\n",
            "--- Adult TEST QC ---\n",
            "Label distribution:\n",
            "label\n",
            "0    12434\n",
            "1     3846\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "Top-10 columns by missing values:\n",
            "age               0\n",
            "workclass         0\n",
            "age_bin           0\n",
            "label             0\n",
            "income            0\n",
            "native-country    0\n",
            "hours-per-week    0\n",
            "capital-loss      0\n",
            "capital-gain      0\n",
            "sex               0\n",
            "dtype: int64\n",
            "\n",
            "--- Kaggle (raw, before split) QC ---\n",
            "Label distribution:\n",
            "label\n",
            "0    1035\n",
            "1     465\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "Top-10 columns by missing values:\n",
            "Age                    0\n",
            "Gender                 0\n",
            "EducationLevel         0\n",
            "ExperienceYears        0\n",
            "PreviousCompanies      0\n",
            "DistanceFromCompany    0\n",
            "InterviewScore         0\n",
            "SkillScore             0\n",
            "PersonalityScore       0\n",
            "RecruitmentStrategy    0\n",
            "dtype: int64\n",
            "Step 2 done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: Feature engineering + Baseline logistic regression\n",
        "\n",
        "\n",
        "# 3.0 Utility: drop overlapping rows in Adult test (hash-based)\n",
        "def drop_overlaps(train_df, test_df):\n",
        "    common_cols = sorted(set(train_df.columns) & set(test_df.columns))\n",
        "    if not common_cols:\n",
        "        return test_df, 0\n",
        "    tr_hash = pd.util.hash_pandas_object(train_df[common_cols], index=False)\n",
        "    te_hash = pd.util.hash_pandas_object(test_df[common_cols], index=False)\n",
        "    mask_keep = ~test_df.index.isin(test_df.index[np.where(te_hash.isin(tr_hash))[0]])\n",
        "    removed = (~mask_keep).sum()\n",
        "    return test_df[mask_keep].reset_index(drop=True), int(removed)\n",
        "\n",
        "# 3.1 Prepare Adult features\n",
        "adult_base_drop = ['label', 'age_bin', 'edu_bin', 'income']\n",
        "adult_leaks = []\n",
        "\n",
        "adult_drop_cols = adult_base_drop + adult_leaks\n",
        "adult_X_cols = [c for c in train_df.columns if c not in adult_drop_cols]\n",
        "\n",
        "adult_num_cols = [c for c in adult_X_cols if train_df[c].dtype.kind in 'if']\n",
        "adult_cat_cols = [c for c in adult_X_cols if c not in adult_num_cols]\n",
        "\n",
        "adult_preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imp', SimpleImputer(strategy='median')),\n",
        "            ('sc', StandardScaler())\n",
        "        ]), adult_num_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "            ('oh', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), adult_cat_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Drop overlaps in Adult test\n",
        "adult_test_dedup, removed_n = drop_overlaps(train_df, test_df)\n",
        "print(f'[Adult] Removed {removed_n} overlapping rows from test set (if any).')\n",
        "\n",
        "# Fit transform Adult\n",
        "X_tr_ad = train_df[adult_X_cols].copy()\n",
        "y_tr_ad = train_df['label'].astype(int).values\n",
        "X_te_ad = adult_test_dedup[adult_X_cols].copy()\n",
        "y_te_ad = adult_test_dedup['label'].astype(int).values\n",
        "\n",
        "X_tr_ad_t = adult_preprocess.fit_transform(X_tr_ad)\n",
        "X_te_ad_t = adult_preprocess.transform(X_te_ad)\n",
        "\n",
        "# Train baseline model (Adult)\n",
        "clf_ad = LogisticRegression(max_iter=300, random_state=SEED)\n",
        "clf_ad.fit(X_tr_ad_t, y_tr_ad)\n",
        "y_score_ad = clf_ad.predict_proba(X_te_ad_t)[:, 1]\n",
        "y_pred_ad  = (y_score_ad >= 0.5).astype(int)\n",
        "\n",
        "perf_ad = {\n",
        "    'accuracy': accuracy_score(y_te_ad, y_pred_ad),\n",
        "    'f1': f1_score(y_te_ad, y_pred_ad),\n",
        "    'auc': roc_auc_score(y_te_ad, y_score_ad)\n",
        "}\n",
        "print('[Adult] Baseline performance:', perf_ad)\n",
        "\n",
        "# Adult fairness metrics (age, edu)\n",
        "def to_bld(X_np, y, prot_name, prot_vals):\n",
        "    df_tmp = pd.DataFrame(X_np)\n",
        "    df_tmp['label'] = y\n",
        "    df_tmp[prot_name] = prot_vals\n",
        "    return BinaryLabelDataset(\n",
        "        df=df_tmp,\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=[prot_name],\n",
        "        favorable_label=1, unfavorable_label=0\n",
        "    )\n",
        "\n",
        "def fairness_report(bld_true, bld_pred, prot_name, unpriv=1, priv=0):\n",
        "    cm = ClassificationMetric(\n",
        "        bld_true, bld_pred,\n",
        "        unprivileged_groups=[{prot_name: unpriv}],\n",
        "        privileged_groups=[{prot_name: priv}]\n",
        "    )\n",
        "    return {\n",
        "        'SPD': cm.statistical_parity_difference(),\n",
        "        'EOD': cm.equal_opportunity_difference(),\n",
        "        'DI':  cm.disparate_impact()\n",
        "    }\n",
        "\n",
        "p_te_ad_age = adult_test_dedup['age_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_te_ad_edu = adult_test_dedup['edu_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "\n",
        "bld_te_age_ad   = to_bld(X_te_ad_t, y_te_ad, 'age_bin', p_te_ad_age)\n",
        "bld_pred_age_ad = to_bld(X_te_ad_t, y_pred_ad, 'age_bin', p_te_ad_age)\n",
        "fair_age_ad = fairness_report(bld_te_age_ad, bld_pred_age_ad, 'age_bin')\n",
        "print('[Adult] Fairness (Age):', fair_age_ad)\n",
        "\n",
        "bld_te_edu_ad   = to_bld(X_te_ad_t, y_te_ad, 'edu_bin', p_te_ad_edu)\n",
        "bld_pred_edu_ad = to_bld(X_te_ad_t, y_pred_ad, 'edu_bin', p_te_ad_edu)\n",
        "fair_edu_ad = fairness_report(bld_te_edu_ad, bld_pred_edu_ad, 'edu_bin')\n",
        "print('[Adult] Fairness (Education):', fair_edu_ad)\n",
        "\n",
        "# 3.2 Kaggle: stratified train/test split, build pipeline, train baseline\n",
        "kaggle_base_drop = ['label', 'age_bin', 'edu_bin', 'education_ord', 'HiringDecision']\n",
        "kaggle_leaks = []\n",
        "kaggle_drop_cols = kaggle_base_drop + kaggle_leaks\n",
        "\n",
        "kaggle_X_cols = [c for c in kaggle_df.columns if c not in kaggle_drop_cols]\n",
        "kaggle_num_cols = [c for c in kaggle_X_cols if kaggle_df[c].dtype.kind in 'if']\n",
        "kaggle_cat_cols = [c for c in kaggle_X_cols if c not in kaggle_num_cols]\n",
        "\n",
        "kaggle_preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imp', SimpleImputer(strategy='median')),\n",
        "            ('sc', StandardScaler())\n",
        "        ]), kaggle_num_cols),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "            ('oh', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), kaggle_cat_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Split Kaggle\n",
        "tr_kg, te_kg = train_test_split(\n",
        "    kaggle_df, test_size=0.2, random_state=SEED, stratify=kaggle_df['label']\n",
        ")\n",
        "\n",
        "X_tr_kg = tr_kg[kaggle_X_cols].copy(); y_tr_kg = tr_kg['label'].astype(int).values\n",
        "X_te_kg = te_kg[kaggle_X_cols].copy(); y_te_kg = te_kg['label'].astype(int).values\n",
        "\n",
        "X_tr_kg_t = kaggle_preprocess.fit_transform(X_tr_kg)\n",
        "X_te_kg_t = kaggle_preprocess.transform(X_te_kg)\n",
        "\n",
        "# Train baseline (Kaggle)\n",
        "clf_kg = LogisticRegression(max_iter=300, random_state=SEED)\n",
        "clf_kg.fit(X_tr_kg_t, y_tr_kg)\n",
        "y_score_kg = clf_kg.predict_proba(X_te_kg_t)[:, 1]\n",
        "y_pred_kg  = (y_score_kg >= 0.5).astype(int)\n",
        "\n",
        "perf_kg = {\n",
        "    'accuracy': accuracy_score(y_te_kg, y_pred_kg),\n",
        "    'f1': f1_score(y_te_kg, y_pred_kg),\n",
        "    'auc': roc_auc_score(y_te_kg, y_score_kg)\n",
        "}\n",
        "print('[Kaggle] Baseline performance:', perf_kg)\n",
        "\n",
        "# Kaggle fairness (age & edu)\n",
        "p_te_kg_age = te_kg['age_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_te_kg_edu = te_kg['edu_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "\n",
        "bld_te_age_kg   = to_bld(X_te_kg_t, y_te_kg, 'age_bin', p_te_kg_age)\n",
        "bld_pred_age_kg = to_bld(X_te_kg_t, y_pred_kg, 'age_bin', p_te_kg_age)\n",
        "fair_age_kg = fairness_report(bld_te_age_kg, bld_pred_age_kg, 'age_bin')\n",
        "print('[Kaggle] Fairness (Age):', fair_age_kg)\n",
        "\n",
        "bld_te_edu_kg   = to_bld(X_te_kg_t, y_te_kg, 'edu_bin', p_te_kg_edu)\n",
        "bld_pred_edu_kg = to_bld(X_te_kg_t, y_pred_kg, 'edu_bin', p_te_kg_edu)\n",
        "fair_edu_kg = fairness_report(bld_te_edu_kg, bld_pred_edu_kg, 'edu_bin')\n",
        "print('[Kaggle] Fairness (Education):', fair_edu_kg)\n",
        "\n",
        "print('Step 3 complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4UOx3Epu4qi",
        "outputId": "ca12e45c-b513-4372-8e89-c511ec027b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adult] Removed 23 overlapping rows from test set (if any).\n",
            "[Adult] Baseline performance: {'accuracy': 0.852924893891862, 'f1': 0.657988842797883, 'auc': 0.9053385929054687}\n",
            "[Adult] Fairness (Age): {'SPD': -0.18588232223274836, 'EOD': -0.12899178728284322, 'DI': 0.3757110369686625}\n",
            "[Adult] Fairness (Education): {'SPD': -0.43415169294206646, 'EOD': -0.4791272424546021, 'DI': 0.16520427217047143}\n",
            "[Kaggle] Baseline performance: {'accuracy': 0.8566666666666667, 'f1': 0.7514450867052023, 'auc': 0.8911225390888785}\n",
            "[Kaggle] Fairness (Age): {'SPD': 0.006030453791647794, 'EOD': -0.050793650793650724, 'DI': 1.0229621125143513}\n",
            "[Kaggle] Fairness (Education): {'SPD': -0.2644087938205585, 'EOD': -0.16187384044526898, 'DI': 0.4006734006734007}\n",
            "Step 3 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Debiasing methods comparison (Reweighing / Adversarial Debiasing / Reject Option Classification)\n",
        "\n",
        "\n",
        "\n",
        "# 4.0 Helpers\n",
        "\n",
        "def compute_performance(y_true, y_pred, y_score):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'f1': f1_score(y_true, y_pred),\n",
        "        'auc': roc_auc_score(y_true, y_score) if len(np.unique(y_true)) == 2 else np.nan\n",
        "    }\n",
        "\n",
        "def to_bld_from_arrays(X, y, prot, prot_name='prot'):\n",
        "    \"\"\"Build an AIF360 BinaryLabelDataset from numpy arrays (features + label + protected).\"\"\"\n",
        "\n",
        "    cols = [f'f{i}' for i in range(X.shape[1])]\n",
        "    df = pd.DataFrame(X, columns=cols)\n",
        "    df['label'] = y\n",
        "    df[prot_name] = prot\n",
        "    bld = BinaryLabelDataset(\n",
        "        df=df,\n",
        "        label_names=['label'],\n",
        "        protected_attribute_names=[prot_name],\n",
        "        favorable_label=1,\n",
        "        unfavorable_label=0\n",
        "    )\n",
        "    return bld\n",
        "\n",
        "def fairness_report(bld_true, bld_pred, prot_name, unpriv=1, priv=0):\n",
        "    cm = ClassificationMetric(\n",
        "        bld_true, bld_pred,\n",
        "        unprivileged_groups=[{prot_name: unpriv}],\n",
        "        privileged_groups=[{prot_name: priv}]\n",
        "    )\n",
        "    return {\n",
        "        'SPD': cm.statistical_parity_difference(),\n",
        "        'EOD': cm.equal_opportunity_difference(),\n",
        "        'DI':  cm.disparate_impact()\n",
        "    }\n",
        "\n",
        "def print_block(title, obj):\n",
        "    print('\\n' + '='*90)\n",
        "    print(title)\n",
        "    print('='*90)\n",
        "    print(obj)\n",
        "\n",
        "# 4.1 Prepare protected attributes (train & test) for both datasets\n",
        "\n",
        "# Adult train protected attributes\n",
        "p_tr_ad_age = train_df['age_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_tr_ad_edu = train_df['edu_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "\n",
        "# Adult test protected attributes\n",
        "# Kaggle train/test protected attributes\n",
        "p_tr_kg_age = tr_kg['age_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_tr_kg_edu = tr_kg['edu_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_te_kg_age = te_kg['age_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "p_te_kg_edu = te_kg['edu_bin'].astype('Int64').fillna(0).astype(int).values\n",
        "\n",
        "# 4.2 REWEIGHING (pre-processing)\n",
        "# Train logistic regression using instance weights produced by Reweighing.\n",
        "\n",
        "def run_reweighing(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name):\n",
        "\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    rw = Reweighing(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}]\n",
        "    )\n",
        "    bld_tr_rw = rw.fit_transform(bld_tr)\n",
        "    sample_w = bld_tr_rw.instance_weights\n",
        "\n",
        "\n",
        "    clf = LogisticRegression(max_iter=300, random_state=SEED)\n",
        "    clf.fit(X_tr, y_tr, sample_weight=sample_w)\n",
        "    y_score = clf.predict_proba(X_te)[:, 1]\n",
        "    y_pred = (y_score >= 0.5).astype(int)\n",
        "\n",
        "\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_pred = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te_true, bld_te_pred, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "# 4.3 ADVERSARIAL DEBIASING (in-processing)\n",
        "# Train a debiased classifier in TensorFlow via AIF360.\n",
        "\n",
        "def run_adversarial(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, scope):\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    bld_te = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    sess = tf.compat.v1.Session()\n",
        "    np.random.seed(SEED)\n",
        "    tf.compat.v1.set_random_seed(SEED)\n",
        "\n",
        "    debias = AdversarialDebiasing(\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        scope_name=scope,\n",
        "        debias=True,\n",
        "        sess=sess,\n",
        "        num_epochs=50,\n",
        "        batch_size=256,\n",
        "        classifier_num_hidden_units=64\n",
        "    )\n",
        "    debias.fit(bld_tr)\n",
        "\n",
        "\n",
        "    bld_pred = debias.predict(bld_te)\n",
        "\n",
        "\n",
        "    y_pred = bld_pred.labels.ravel().astype(int)\n",
        "\n",
        "    y_score = bld_pred.scores.ravel()\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te, bld_pred, prot_name)\n",
        "\n",
        "    sess.close()\n",
        "    return perf, fair\n",
        "\n",
        "# 4.4 REJECT OPTION CLASSIFICATION (post-processing)\n",
        "\n",
        "\n",
        "def run_roc_postproc(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name):\n",
        "    base = LogisticRegression(max_iter=300, random_state=SEED)\n",
        "    base.fit(X_tr, y_tr)\n",
        "    y_score = base.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    # Build AIF360 datasets\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_scores = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "    # Attach the continuous scores for ROC to use\n",
        "    bld_te_scores.scores = y_score.reshape(-1, 1)\n",
        "\n",
        "    roc = RejectOptionClassification(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        metric_name=\"Statistical parity difference\",\n",
        "        metric_lb=-0.02,\n",
        "        metric_ub=0.02,\n",
        "        num_class_thresh=100,\n",
        "        num_ROC_margin=50\n",
        "    )\n",
        "    roc = roc.fit(bld_te_true, bld_te_scores)\n",
        "    bld_post = roc.predict(bld_te_scores)\n",
        "\n",
        "    # Extract for performance\n",
        "    y_pred_post = bld_post.labels.ravel().astype(int)\n",
        "    y_score_post = getattr(bld_post, 'scores', None)\n",
        "    if y_score_post is None:\n",
        "        y_score_post = y_score\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred_post, y_score_post)\n",
        "    fair = fairness_report(bld_te_true, bld_post, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "# 4.5 Run all methods on BOTH datasets and BOTH protected attributes\n",
        "\n",
        "results = []\n",
        "\n",
        "def run_all_for_dataset(name, X_tr, y_tr, X_te, y_te, p_tr_age, p_te_age, p_tr_edu, p_te_edu):\n",
        "    # Age\n",
        "    perf_rw, fair_rw = run_reweighing(X_tr, y_tr, X_te, y_te, p_tr_age, p_te_age, 'age_bin')\n",
        "    results.append((name, 'age_bin', 'Reweighing', perf_rw, fair_rw))\n",
        "\n",
        "    perf_adv, fair_adv = run_adversarial(X_tr, y_tr, X_te, y_te, p_tr_age, p_te_age, 'age_bin', scope=f'adv_{name}_age')\n",
        "    results.append((name, 'age_bin', 'Adversarial', perf_adv, fair_adv))\n",
        "\n",
        "    perf_roc, fair_roc = run_roc_postproc(X_tr, y_tr, X_te, y_te, p_tr_age, p_te_age, 'age_bin')\n",
        "    results.append((name, 'age_bin', 'ROC_post', perf_roc, fair_roc))\n",
        "\n",
        "    # Education\n",
        "    perf_rw, fair_rw = run_reweighing(X_tr, y_tr, X_te, y_te, p_tr_edu, p_te_edu, 'edu_bin')\n",
        "    results.append((name, 'edu_bin', 'Reweighing', perf_rw, fair_rw))\n",
        "\n",
        "    perf_adv, fair_adv = run_adversarial(X_tr, y_tr, X_te, y_te, p_tr_edu, p_te_edu, 'edu_bin', scope=f'adv_{name}_edu')\n",
        "    results.append((name, 'edu_bin', 'Adversarial', perf_adv, fair_adv))\n",
        "\n",
        "    perf_roc, fair_roc = run_roc_postproc(X_tr, y_tr, X_te, y_te, p_tr_edu, p_te_edu, 'edu_bin')\n",
        "    results.append((name, 'edu_bin', 'ROC_post', perf_roc, fair_roc))\n",
        "\n",
        "\n",
        "# Adult dataset runs\n",
        "run_all_for_dataset(\n",
        "    'Adult',\n",
        "    X_tr_ad_t, y_tr_ad, X_te_ad_t, y_te_ad,\n",
        "    p_tr_ad_age, p_te_ad_age,\n",
        "    p_tr_ad_edu, p_te_ad_edu\n",
        ")\n",
        "\n",
        "# Kaggle dataset runs\n",
        "run_all_for_dataset(\n",
        "    'Kaggle',\n",
        "    X_tr_kg_t, y_tr_kg, X_te_kg_t, y_te_kg,\n",
        "    p_tr_kg_age, p_te_kg_age,\n",
        "    p_tr_kg_edu, p_te_kg_edu\n",
        ")\n",
        "\n",
        "# 4.6 Pretty print results\n",
        "\n",
        "rows = []\n",
        "for ds, attr, method, perf, fair in results:\n",
        "    rows.append({\n",
        "        'dataset': ds,\n",
        "        'protected_attr': attr,\n",
        "        'method': method,\n",
        "        'accuracy': perf['accuracy'],\n",
        "        'f1': perf['f1'],\n",
        "        'auc': perf['auc'],\n",
        "        'SPD': fair['SPD'], 'EOD': fair['EOD'], 'DI': fair['DI']\n",
        "    })\n",
        "\n",
        "res_df = pd.DataFrame(rows)\n",
        "print_block('DEBIASING COMPARISON RESULTS', res_df)\n",
        "\n",
        "# Also show grouped summary by dataset/attr/method\n",
        "def fmt(x):\n",
        "    return f\"{x['mean']:.3f}\"\n",
        "summary = res_df.groupby(['dataset','protected_attr','method']).agg({\n",
        "    'accuracy':'mean','f1':'mean','auc':'mean','SPD':'mean','EOD':'mean','DI':'mean'\n",
        "}).reset_index()\n",
        "\n",
        "print_block('SUMMARY (mean values)', summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNGCduuowdGU",
        "outputId": "8201eb0c-df57-4860-c995-bbc71f561274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.742295; batch adversarial loss: 0.741474\n",
            "epoch 1; iter: 0; batch classifier loss: 0.347234; batch adversarial loss: 0.714793\n",
            "epoch 2; iter: 0; batch classifier loss: 0.305107; batch adversarial loss: 0.727259\n",
            "epoch 3; iter: 0; batch classifier loss: 0.288207; batch adversarial loss: 0.700075\n",
            "epoch 4; iter: 0; batch classifier loss: 0.325124; batch adversarial loss: 0.680498\n",
            "epoch 5; iter: 0; batch classifier loss: 0.320235; batch adversarial loss: 0.690856\n",
            "epoch 6; iter: 0; batch classifier loss: 0.356991; batch adversarial loss: 0.674536\n",
            "epoch 7; iter: 0; batch classifier loss: 0.336697; batch adversarial loss: 0.667821\n",
            "epoch 8; iter: 0; batch classifier loss: 0.318562; batch adversarial loss: 0.669220\n",
            "epoch 9; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.689869\n",
            "epoch 10; iter: 0; batch classifier loss: 0.405593; batch adversarial loss: 0.678475\n",
            "epoch 11; iter: 0; batch classifier loss: 0.331877; batch adversarial loss: 0.691435\n",
            "epoch 12; iter: 0; batch classifier loss: 0.345895; batch adversarial loss: 0.688403\n",
            "epoch 13; iter: 0; batch classifier loss: 0.387468; batch adversarial loss: 0.679491\n",
            "epoch 14; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.680181\n",
            "epoch 15; iter: 0; batch classifier loss: 0.386516; batch adversarial loss: 0.670319\n",
            "epoch 16; iter: 0; batch classifier loss: 0.311977; batch adversarial loss: 0.657381\n",
            "epoch 17; iter: 0; batch classifier loss: 0.331805; batch adversarial loss: 0.662799\n",
            "epoch 18; iter: 0; batch classifier loss: 0.310803; batch adversarial loss: 0.660151\n",
            "epoch 19; iter: 0; batch classifier loss: 0.312193; batch adversarial loss: 0.668826\n",
            "epoch 20; iter: 0; batch classifier loss: 0.379135; batch adversarial loss: 0.673546\n",
            "epoch 21; iter: 0; batch classifier loss: 0.298723; batch adversarial loss: 0.679986\n",
            "epoch 22; iter: 0; batch classifier loss: 0.365342; batch adversarial loss: 0.674309\n",
            "epoch 23; iter: 0; batch classifier loss: 0.291420; batch adversarial loss: 0.665555\n",
            "epoch 24; iter: 0; batch classifier loss: 0.329749; batch adversarial loss: 0.685197\n",
            "epoch 25; iter: 0; batch classifier loss: 0.306080; batch adversarial loss: 0.653100\n",
            "epoch 26; iter: 0; batch classifier loss: 0.367065; batch adversarial loss: 0.668207\n",
            "epoch 27; iter: 0; batch classifier loss: 0.394778; batch adversarial loss: 0.670432\n",
            "epoch 28; iter: 0; batch classifier loss: 0.349713; batch adversarial loss: 0.667708\n",
            "epoch 29; iter: 0; batch classifier loss: 0.401584; batch adversarial loss: 0.676091\n",
            "epoch 30; iter: 0; batch classifier loss: 0.246206; batch adversarial loss: 0.677966\n",
            "epoch 31; iter: 0; batch classifier loss: 0.292076; batch adversarial loss: 0.649498\n",
            "epoch 32; iter: 0; batch classifier loss: 0.261261; batch adversarial loss: 0.669328\n",
            "epoch 33; iter: 0; batch classifier loss: 0.322525; batch adversarial loss: 0.666132\n",
            "epoch 34; iter: 0; batch classifier loss: 0.287684; batch adversarial loss: 0.662863\n",
            "epoch 35; iter: 0; batch classifier loss: 0.248542; batch adversarial loss: 0.671668\n",
            "epoch 36; iter: 0; batch classifier loss: 0.310497; batch adversarial loss: 0.659067\n",
            "epoch 37; iter: 0; batch classifier loss: 0.418716; batch adversarial loss: 0.677573\n",
            "epoch 38; iter: 0; batch classifier loss: 0.257026; batch adversarial loss: 0.656448\n",
            "epoch 39; iter: 0; batch classifier loss: 0.330993; batch adversarial loss: 0.685365\n",
            "epoch 40; iter: 0; batch classifier loss: 0.307636; batch adversarial loss: 0.684628\n",
            "epoch 41; iter: 0; batch classifier loss: 0.318485; batch adversarial loss: 0.662307\n",
            "epoch 42; iter: 0; batch classifier loss: 0.279125; batch adversarial loss: 0.679379\n",
            "epoch 43; iter: 0; batch classifier loss: 0.313441; batch adversarial loss: 0.673530\n",
            "epoch 44; iter: 0; batch classifier loss: 0.268274; batch adversarial loss: 0.661268\n",
            "epoch 45; iter: 0; batch classifier loss: 0.239769; batch adversarial loss: 0.664820\n",
            "epoch 46; iter: 0; batch classifier loss: 0.274977; batch adversarial loss: 0.684569\n",
            "epoch 47; iter: 0; batch classifier loss: 0.295873; batch adversarial loss: 0.654264\n",
            "epoch 48; iter: 0; batch classifier loss: 0.329025; batch adversarial loss: 0.664649\n",
            "epoch 49; iter: 0; batch classifier loss: 0.304495; batch adversarial loss: 0.671849\n",
            "epoch 0; iter: 0; batch classifier loss: 0.740934; batch adversarial loss: 0.694945\n",
            "epoch 1; iter: 0; batch classifier loss: 0.359753; batch adversarial loss: 0.678787\n",
            "epoch 2; iter: 0; batch classifier loss: 0.300886; batch adversarial loss: 0.665004\n",
            "epoch 3; iter: 0; batch classifier loss: 0.294110; batch adversarial loss: 0.642769\n",
            "epoch 4; iter: 0; batch classifier loss: 0.325714; batch adversarial loss: 0.634272\n",
            "epoch 5; iter: 0; batch classifier loss: 0.323409; batch adversarial loss: 0.584852\n",
            "epoch 6; iter: 0; batch classifier loss: 0.355342; batch adversarial loss: 0.587572\n",
            "epoch 7; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.559186\n",
            "epoch 8; iter: 0; batch classifier loss: 0.303172; batch adversarial loss: 0.549618\n",
            "epoch 9; iter: 0; batch classifier loss: 0.351411; batch adversarial loss: 0.535327\n",
            "epoch 10; iter: 0; batch classifier loss: 0.350764; batch adversarial loss: 0.502521\n",
            "epoch 11; iter: 0; batch classifier loss: 0.308151; batch adversarial loss: 0.611228\n",
            "epoch 12; iter: 0; batch classifier loss: 0.292686; batch adversarial loss: 0.550146\n",
            "epoch 13; iter: 0; batch classifier loss: 0.341654; batch adversarial loss: 0.527553\n",
            "epoch 14; iter: 0; batch classifier loss: 0.300191; batch adversarial loss: 0.516772\n",
            "epoch 15; iter: 0; batch classifier loss: 0.359152; batch adversarial loss: 0.572517\n",
            "epoch 16; iter: 0; batch classifier loss: 0.304806; batch adversarial loss: 0.533634\n",
            "epoch 17; iter: 0; batch classifier loss: 0.324238; batch adversarial loss: 0.492593\n",
            "epoch 18; iter: 0; batch classifier loss: 0.306887; batch adversarial loss: 0.544253\n",
            "epoch 19; iter: 0; batch classifier loss: 0.328428; batch adversarial loss: 0.570361\n",
            "epoch 20; iter: 0; batch classifier loss: 0.358258; batch adversarial loss: 0.525554\n",
            "epoch 21; iter: 0; batch classifier loss: 0.301352; batch adversarial loss: 0.557591\n",
            "epoch 22; iter: 0; batch classifier loss: 0.342608; batch adversarial loss: 0.522780\n",
            "epoch 23; iter: 0; batch classifier loss: 0.278470; batch adversarial loss: 0.496450\n",
            "epoch 24; iter: 0; batch classifier loss: 0.333770; batch adversarial loss: 0.497813\n",
            "epoch 25; iter: 0; batch classifier loss: 0.302512; batch adversarial loss: 0.485009\n",
            "epoch 26; iter: 0; batch classifier loss: 0.342162; batch adversarial loss: 0.520328\n",
            "epoch 27; iter: 0; batch classifier loss: 0.378010; batch adversarial loss: 0.570512\n",
            "epoch 28; iter: 0; batch classifier loss: 0.343456; batch adversarial loss: 0.510498\n",
            "epoch 29; iter: 0; batch classifier loss: 0.405529; batch adversarial loss: 0.487230\n",
            "epoch 30; iter: 0; batch classifier loss: 0.288964; batch adversarial loss: 0.539297\n",
            "epoch 31; iter: 0; batch classifier loss: 0.294129; batch adversarial loss: 0.481177\n",
            "epoch 32; iter: 0; batch classifier loss: 0.265947; batch adversarial loss: 0.501921\n",
            "epoch 33; iter: 0; batch classifier loss: 0.330025; batch adversarial loss: 0.523676\n",
            "epoch 34; iter: 0; batch classifier loss: 0.291695; batch adversarial loss: 0.581516\n",
            "epoch 35; iter: 0; batch classifier loss: 0.238413; batch adversarial loss: 0.508255\n",
            "epoch 36; iter: 0; batch classifier loss: 0.292109; batch adversarial loss: 0.499566\n",
            "epoch 37; iter: 0; batch classifier loss: 0.370610; batch adversarial loss: 0.548676\n",
            "epoch 38; iter: 0; batch classifier loss: 0.261345; batch adversarial loss: 0.444405\n",
            "epoch 39; iter: 0; batch classifier loss: 0.323170; batch adversarial loss: 0.498282\n",
            "epoch 40; iter: 0; batch classifier loss: 0.300176; batch adversarial loss: 0.531519\n",
            "epoch 41; iter: 0; batch classifier loss: 0.320036; batch adversarial loss: 0.467953\n",
            "epoch 42; iter: 0; batch classifier loss: 0.270821; batch adversarial loss: 0.541866\n",
            "epoch 43; iter: 0; batch classifier loss: 0.297326; batch adversarial loss: 0.502568\n",
            "epoch 44; iter: 0; batch classifier loss: 0.251398; batch adversarial loss: 0.548436\n",
            "epoch 45; iter: 0; batch classifier loss: 0.246426; batch adversarial loss: 0.491615\n",
            "epoch 46; iter: 0; batch classifier loss: 0.269784; batch adversarial loss: 0.501420\n",
            "epoch 47; iter: 0; batch classifier loss: 0.314344; batch adversarial loss: 0.460123\n",
            "epoch 48; iter: 0; batch classifier loss: 0.314167; batch adversarial loss: 0.556121\n",
            "epoch 49; iter: 0; batch classifier loss: 0.308043; batch adversarial loss: 0.477002\n",
            "epoch 0; iter: 0; batch classifier loss: 0.896412; batch adversarial loss: 0.696458\n",
            "epoch 1; iter: 0; batch classifier loss: 0.843614; batch adversarial loss: 0.670863\n",
            "epoch 2; iter: 0; batch classifier loss: 0.864863; batch adversarial loss: 0.660115\n",
            "epoch 3; iter: 0; batch classifier loss: 0.810308; batch adversarial loss: 0.660333\n",
            "epoch 4; iter: 0; batch classifier loss: 0.758222; batch adversarial loss: 0.663698\n",
            "epoch 5; iter: 0; batch classifier loss: 0.724666; batch adversarial loss: 0.679846\n",
            "epoch 6; iter: 0; batch classifier loss: 0.697580; batch adversarial loss: 0.682563\n",
            "epoch 7; iter: 0; batch classifier loss: 0.710323; batch adversarial loss: 0.649437\n",
            "epoch 8; iter: 0; batch classifier loss: 0.662141; batch adversarial loss: 0.698299\n",
            "epoch 9; iter: 0; batch classifier loss: 0.646967; batch adversarial loss: 0.676430\n",
            "epoch 10; iter: 0; batch classifier loss: 0.629738; batch adversarial loss: 0.679103\n",
            "epoch 11; iter: 0; batch classifier loss: 0.611379; batch adversarial loss: 0.658841\n",
            "epoch 12; iter: 0; batch classifier loss: 0.594450; batch adversarial loss: 0.673015\n",
            "epoch 13; iter: 0; batch classifier loss: 0.559447; batch adversarial loss: 0.662134\n",
            "epoch 14; iter: 0; batch classifier loss: 0.537868; batch adversarial loss: 0.684550\n",
            "epoch 15; iter: 0; batch classifier loss: 0.547917; batch adversarial loss: 0.674745\n",
            "epoch 16; iter: 0; batch classifier loss: 0.545810; batch adversarial loss: 0.663069\n",
            "epoch 17; iter: 0; batch classifier loss: 0.501081; batch adversarial loss: 0.655717\n",
            "epoch 18; iter: 0; batch classifier loss: 0.506343; batch adversarial loss: 0.678527\n",
            "epoch 19; iter: 0; batch classifier loss: 0.522165; batch adversarial loss: 0.686467\n",
            "epoch 20; iter: 0; batch classifier loss: 0.510378; batch adversarial loss: 0.680959\n",
            "epoch 21; iter: 0; batch classifier loss: 0.470318; batch adversarial loss: 0.642509\n",
            "epoch 22; iter: 0; batch classifier loss: 0.496801; batch adversarial loss: 0.679424\n",
            "epoch 23; iter: 0; batch classifier loss: 0.467022; batch adversarial loss: 0.687800\n",
            "epoch 24; iter: 0; batch classifier loss: 0.490475; batch adversarial loss: 0.689605\n",
            "epoch 25; iter: 0; batch classifier loss: 0.478071; batch adversarial loss: 0.658493\n",
            "epoch 26; iter: 0; batch classifier loss: 0.455903; batch adversarial loss: 0.657332\n",
            "epoch 27; iter: 0; batch classifier loss: 0.458209; batch adversarial loss: 0.640404\n",
            "epoch 28; iter: 0; batch classifier loss: 0.388906; batch adversarial loss: 0.676220\n",
            "epoch 29; iter: 0; batch classifier loss: 0.426094; batch adversarial loss: 0.679032\n",
            "epoch 30; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.655986\n",
            "epoch 31; iter: 0; batch classifier loss: 0.437505; batch adversarial loss: 0.673023\n",
            "epoch 32; iter: 0; batch classifier loss: 0.449662; batch adversarial loss: 0.683700\n",
            "epoch 33; iter: 0; batch classifier loss: 0.391359; batch adversarial loss: 0.670200\n",
            "epoch 34; iter: 0; batch classifier loss: 0.436974; batch adversarial loss: 0.669892\n",
            "epoch 35; iter: 0; batch classifier loss: 0.411197; batch adversarial loss: 0.657672\n",
            "epoch 36; iter: 0; batch classifier loss: 0.376670; batch adversarial loss: 0.661477\n",
            "epoch 37; iter: 0; batch classifier loss: 0.403297; batch adversarial loss: 0.668063\n",
            "epoch 38; iter: 0; batch classifier loss: 0.412491; batch adversarial loss: 0.643947\n",
            "epoch 39; iter: 0; batch classifier loss: 0.421504; batch adversarial loss: 0.667734\n",
            "epoch 40; iter: 0; batch classifier loss: 0.382207; batch adversarial loss: 0.678336\n",
            "epoch 41; iter: 0; batch classifier loss: 0.357281; batch adversarial loss: 0.656463\n",
            "epoch 42; iter: 0; batch classifier loss: 0.421695; batch adversarial loss: 0.661669\n",
            "epoch 43; iter: 0; batch classifier loss: 0.448273; batch adversarial loss: 0.668966\n",
            "epoch 44; iter: 0; batch classifier loss: 0.388909; batch adversarial loss: 0.653383\n",
            "epoch 45; iter: 0; batch classifier loss: 0.400441; batch adversarial loss: 0.674013\n",
            "epoch 46; iter: 0; batch classifier loss: 0.423864; batch adversarial loss: 0.654136\n",
            "epoch 47; iter: 0; batch classifier loss: 0.424544; batch adversarial loss: 0.630881\n",
            "epoch 48; iter: 0; batch classifier loss: 0.399277; batch adversarial loss: 0.655982\n",
            "epoch 49; iter: 0; batch classifier loss: 0.367243; batch adversarial loss: 0.664271\n",
            "epoch 0; iter: 0; batch classifier loss: 0.911781; batch adversarial loss: 0.728136\n",
            "epoch 1; iter: 0; batch classifier loss: 0.860237; batch adversarial loss: 0.662151\n",
            "epoch 2; iter: 0; batch classifier loss: 0.877128; batch adversarial loss: 0.690151\n",
            "epoch 3; iter: 0; batch classifier loss: 0.823755; batch adversarial loss: 0.686436\n",
            "epoch 4; iter: 0; batch classifier loss: 0.772509; batch adversarial loss: 0.686628\n",
            "epoch 5; iter: 0; batch classifier loss: 0.737889; batch adversarial loss: 0.698064\n",
            "epoch 6; iter: 0; batch classifier loss: 0.712719; batch adversarial loss: 0.690722\n",
            "epoch 7; iter: 0; batch classifier loss: 0.710751; batch adversarial loss: 0.681683\n",
            "epoch 8; iter: 0; batch classifier loss: 0.668392; batch adversarial loss: 0.664589\n",
            "epoch 9; iter: 0; batch classifier loss: 0.657602; batch adversarial loss: 0.675009\n",
            "epoch 10; iter: 0; batch classifier loss: 0.639861; batch adversarial loss: 0.689810\n",
            "epoch 11; iter: 0; batch classifier loss: 0.628167; batch adversarial loss: 0.678102\n",
            "epoch 12; iter: 0; batch classifier loss: 0.615458; batch adversarial loss: 0.684575\n",
            "epoch 13; iter: 0; batch classifier loss: 0.567573; batch adversarial loss: 0.672528\n",
            "epoch 14; iter: 0; batch classifier loss: 0.547402; batch adversarial loss: 0.680038\n",
            "epoch 15; iter: 0; batch classifier loss: 0.568895; batch adversarial loss: 0.661264\n",
            "epoch 16; iter: 0; batch classifier loss: 0.576439; batch adversarial loss: 0.673576\n",
            "epoch 17; iter: 0; batch classifier loss: 0.547146; batch adversarial loss: 0.677464\n",
            "epoch 18; iter: 0; batch classifier loss: 0.530911; batch adversarial loss: 0.670964\n",
            "epoch 19; iter: 0; batch classifier loss: 0.540976; batch adversarial loss: 0.676902\n",
            "epoch 20; iter: 0; batch classifier loss: 0.534050; batch adversarial loss: 0.687045\n",
            "epoch 21; iter: 0; batch classifier loss: 0.498760; batch adversarial loss: 0.661569\n",
            "epoch 22; iter: 0; batch classifier loss: 0.499081; batch adversarial loss: 0.661041\n",
            "epoch 23; iter: 0; batch classifier loss: 0.501281; batch adversarial loss: 0.668400\n",
            "epoch 24; iter: 0; batch classifier loss: 0.504171; batch adversarial loss: 0.655189\n",
            "epoch 25; iter: 0; batch classifier loss: 0.493494; batch adversarial loss: 0.675798\n",
            "epoch 26; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.672440\n",
            "epoch 27; iter: 0; batch classifier loss: 0.486954; batch adversarial loss: 0.705339\n",
            "epoch 28; iter: 0; batch classifier loss: 0.400162; batch adversarial loss: 0.692650\n",
            "epoch 29; iter: 0; batch classifier loss: 0.452249; batch adversarial loss: 0.680814\n",
            "epoch 30; iter: 0; batch classifier loss: 0.445018; batch adversarial loss: 0.688727\n",
            "epoch 31; iter: 0; batch classifier loss: 0.443996; batch adversarial loss: 0.666875\n",
            "epoch 32; iter: 0; batch classifier loss: 0.473831; batch adversarial loss: 0.696808\n",
            "epoch 33; iter: 0; batch classifier loss: 0.430260; batch adversarial loss: 0.683369\n",
            "epoch 34; iter: 0; batch classifier loss: 0.448679; batch adversarial loss: 0.672340\n",
            "epoch 35; iter: 0; batch classifier loss: 0.431552; batch adversarial loss: 0.699653\n",
            "epoch 36; iter: 0; batch classifier loss: 0.384967; batch adversarial loss: 0.674678\n",
            "epoch 37; iter: 0; batch classifier loss: 0.401996; batch adversarial loss: 0.656999\n",
            "epoch 38; iter: 0; batch classifier loss: 0.421599; batch adversarial loss: 0.683701\n",
            "epoch 39; iter: 0; batch classifier loss: 0.439980; batch adversarial loss: 0.663864\n",
            "epoch 40; iter: 0; batch classifier loss: 0.385844; batch adversarial loss: 0.707253\n",
            "epoch 41; iter: 0; batch classifier loss: 0.360962; batch adversarial loss: 0.674496\n",
            "epoch 42; iter: 0; batch classifier loss: 0.425287; batch adversarial loss: 0.667213\n",
            "epoch 43; iter: 0; batch classifier loss: 0.457936; batch adversarial loss: 0.683735\n",
            "epoch 44; iter: 0; batch classifier loss: 0.390420; batch adversarial loss: 0.681732\n",
            "epoch 45; iter: 0; batch classifier loss: 0.397980; batch adversarial loss: 0.676615\n",
            "epoch 46; iter: 0; batch classifier loss: 0.428592; batch adversarial loss: 0.685001\n",
            "epoch 47; iter: 0; batch classifier loss: 0.449131; batch adversarial loss: 0.681084\n",
            "epoch 48; iter: 0; batch classifier loss: 0.407161; batch adversarial loss: 0.682089\n",
            "epoch 49; iter: 0; batch classifier loss: 0.394479; batch adversarial loss: 0.689914\n",
            "\n",
            "==========================================================================================\n",
            "DEBIASING COMPARISON RESULTS\n",
            "==========================================================================================\n",
            "   dataset protected_attr       method  accuracy        f1       auc  \\\n",
            "0    Adult        age_bin   Reweighing  0.850772  0.646459  0.899566   \n",
            "1    Adult        age_bin  Adversarial  0.848988  0.641134  0.903116   \n",
            "2    Adult        age_bin     ROC_post  0.777573  0.635851  0.905339   \n",
            "3    Adult        edu_bin   Reweighing  0.831088  0.596651  0.884159   \n",
            "4    Adult        edu_bin  Adversarial  0.841238  0.626537  0.900191   \n",
            "5    Adult        edu_bin     ROC_post  0.764286  0.611043  0.905339   \n",
            "6   Kaggle        age_bin   Reweighing  0.853333  0.747126  0.891642   \n",
            "7   Kaggle        age_bin  Adversarial  0.846667  0.722892  0.884525   \n",
            "8   Kaggle        age_bin     ROC_post  0.846667  0.757895  0.891123   \n",
            "9   Kaggle        edu_bin   Reweighing  0.866667  0.761905  0.887486   \n",
            "10  Kaggle        edu_bin  Adversarial  0.860000  0.740741  0.889201   \n",
            "11  Kaggle        edu_bin     ROC_post  0.820000  0.727273  0.891123   \n",
            "\n",
            "         SPD       EOD        DI  \n",
            "0  -0.114940 -0.000812  0.540433  \n",
            "1  -0.066077  0.110919  0.701633  \n",
            "2  -0.018674  0.176346  0.951488  \n",
            "3  -0.125792  0.025151  0.545889  \n",
            "4  -0.186249 -0.057537  0.433532  \n",
            "5  -0.019757  0.227597  0.948621  \n",
            "6   0.011006 -0.050794  1.041906  \n",
            "7   0.061661  0.017460  1.305224  \n",
            "8   0.015227  0.011111  1.048628  \n",
            "9  -0.141117 -0.012059  0.588745  \n",
            "10 -0.126857  0.026438  0.595644  \n",
            "11 -0.019311  0.083488  0.946765  \n",
            "\n",
            "==========================================================================================\n",
            "SUMMARY (mean values)\n",
            "==========================================================================================\n",
            "   dataset protected_attr       method  accuracy        f1       auc  \\\n",
            "0    Adult        age_bin  Adversarial  0.848988  0.641134  0.903116   \n",
            "1    Adult        age_bin     ROC_post  0.777573  0.635851  0.905339   \n",
            "2    Adult        age_bin   Reweighing  0.850772  0.646459  0.899566   \n",
            "3    Adult        edu_bin  Adversarial  0.841238  0.626537  0.900191   \n",
            "4    Adult        edu_bin     ROC_post  0.764286  0.611043  0.905339   \n",
            "5    Adult        edu_bin   Reweighing  0.831088  0.596651  0.884159   \n",
            "6   Kaggle        age_bin  Adversarial  0.846667  0.722892  0.884525   \n",
            "7   Kaggle        age_bin     ROC_post  0.846667  0.757895  0.891123   \n",
            "8   Kaggle        age_bin   Reweighing  0.853333  0.747126  0.891642   \n",
            "9   Kaggle        edu_bin  Adversarial  0.860000  0.740741  0.889201   \n",
            "10  Kaggle        edu_bin     ROC_post  0.820000  0.727273  0.891123   \n",
            "11  Kaggle        edu_bin   Reweighing  0.866667  0.761905  0.887486   \n",
            "\n",
            "         SPD       EOD        DI  \n",
            "0  -0.066077  0.110919  0.701633  \n",
            "1  -0.018674  0.176346  0.951488  \n",
            "2  -0.114940 -0.000812  0.540433  \n",
            "3  -0.186249 -0.057537  0.433532  \n",
            "4  -0.019757  0.227597  0.948621  \n",
            "5  -0.125792  0.025151  0.545889  \n",
            "6   0.061661  0.017460  1.305224  \n",
            "7   0.015227  0.011111  1.048628  \n",
            "8   0.011006 -0.050794  1.041906  \n",
            "9  -0.126857  0.026438  0.595644  \n",
            "10 -0.019311  0.083488  0.946765  \n",
            "11 -0.141117 -0.012059  0.588745  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5A (Adult only): Repeated runs + significance tests vs Baseline\n",
        "\n",
        "\n",
        "import gc\n",
        "\n",
        "\n",
        "def paired_tests(scores_a, scores_b):\n",
        "    a = np.array(scores_a, dtype=float)\n",
        "    b = np.array(scores_b, dtype=float)\n",
        "    t_p = stats.ttest_rel(a, b, alternative='two-sided').pvalue\n",
        "    try:\n",
        "        w_p = stats.wilcoxon(a, b, alternative='two-sided', zero_method='wilcox').pvalue\n",
        "    except Exception:\n",
        "        w_p = np.nan\n",
        "    return dict(ttest_p=t_p, wilcoxon_p=w_p)\n",
        "\n",
        "def summarize_mean_std(df, group_cols=('dataset','protected_attr','method')):\n",
        "    agg = df.groupby(list(group_cols)).agg(\n",
        "        accuracy_mean=('accuracy','mean'), accuracy_std=('accuracy','std'),\n",
        "        f1_mean=('f1','mean'), f1_std=('f1','std'),\n",
        "        auc_mean=('auc','mean'), auc_std=('auc','std'),\n",
        "        SPD_mean=('SPD','mean'), SPD_std=('SPD','std'),\n",
        "        EOD_mean=('EOD','mean'), EOD_std=('EOD','std'),\n",
        "        DI_mean=('DI','mean'), DI_std=('DI','std'),\n",
        "        runs=('accuracy','count')\n",
        "    ).reset_index()\n",
        "    return agg\n",
        "\n",
        "def print_block(title, obj):\n",
        "    print('\\n' + '='*100)\n",
        "    print(title)\n",
        "    print('='*100)\n",
        "    print(obj)\n",
        "\n",
        "# Local runners\n",
        "\n",
        "def s5_run_baseline(X_tr, y_tr, X_te, y_te, prot_te, prot_name, seed=42):\n",
        "    clf = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    y_score = clf.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_pred = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te_true, bld_te_pred, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_reweighing(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    rw = Reweighing(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}]\n",
        "    )\n",
        "    bld_tr_rw = rw.fit_transform(bld_tr)\n",
        "    sample_w = bld_tr_rw.instance_weights\n",
        "\n",
        "    clf = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    clf.fit(X_tr, y_tr, sample_weight=sample_w)\n",
        "    y_score = clf.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_pred = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te_true, bld_te_pred, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_adversarial(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, scope, seed=42, epochs=30):\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    bld_te = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    sess = tf.compat.v1.Session()\n",
        "    np.random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "    adv = AdversarialDebiasing(\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        scope_name=scope,\n",
        "        debias=True,\n",
        "        sess=sess,\n",
        "        num_epochs=30,\n",
        "        batch_size=256,\n",
        "        classifier_num_hidden_units=64\n",
        "    )\n",
        "    adv.fit(bld_tr)\n",
        "    bld_pred = adv.predict(bld_te)\n",
        "\n",
        "    y_pred = bld_pred.labels.ravel().astype(int)\n",
        "    y_score = bld_pred.scores.ravel()\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te, bld_pred, prot_name)\n",
        "\n",
        "    sess.close()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    gc.collect()\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_roc_postproc(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    base = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    base.fit(X_tr, y_tr)\n",
        "    y_score = base.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true   = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_scores = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "    bld_te_scores.scores = y_score.reshape(-1, 1)\n",
        "\n",
        "    roc = RejectOptionClassification(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        metric_name=\"Statistical parity difference\",\n",
        "        metric_lb=-0.02, metric_ub=0.02,\n",
        "        num_class_thresh=100, num_ROC_margin=50\n",
        "    )\n",
        "    roc = roc.fit(bld_te_true, bld_te_scores)\n",
        "    bld_post = roc.predict(bld_te_scores)\n",
        "\n",
        "    y_pred_post = bld_post.labels.ravel().astype(int)\n",
        "    y_score_post = getattr(bld_post, 'scores', None)\n",
        "    if y_score_post is None:\n",
        "        y_score_post = y_score\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred_post, y_score_post)\n",
        "    fair = fairness_report(bld_te_true, bld_post, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def run_once_for_attr(dataset_name, X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    out = []\n",
        "\n",
        "    perf, fair = s5_run_baseline(X_tr, y_tr, X_te, y_te, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Baseline', **perf, **fair))\n",
        "\n",
        "    perf, fair = s5_run_reweighing(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Reweighing', **perf, **fair))\n",
        "\n",
        "    scope = f\"adv_{dataset_name}_{prot_name}_seed{seed}\"\n",
        "    perf, fair = s5_run_adversarial(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, scope=scope, seed=seed, epochs=30)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Adversarial', **perf, **fair))\n",
        "\n",
        "    perf, fair = s5_run_roc_postproc(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='ROC_post', **perf, **fair))\n",
        "\n",
        "    return out\n",
        "\n",
        "# Adult only repeated runs\n",
        "\n",
        "n_runs = 5  # reduce to 3 if RAM is tight\n",
        "all_rows = []\n",
        "\n",
        "for r in range(n_runs):\n",
        "    seed = 42 + r\n",
        "\n",
        "    # Adult - age_bin\n",
        "    all_rows += run_once_for_attr(\n",
        "        'Adult',\n",
        "        X_tr_ad_t, y_tr_ad, X_te_ad_t, y_te_ad,\n",
        "        p_tr_ad_age, p_te_ad_age,\n",
        "        'age_bin',\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    # Adult - edu_bin\n",
        "    all_rows += run_once_for_attr(\n",
        "        'Adult',\n",
        "        X_tr_ad_t, y_tr_ad, X_te_ad_t, y_te_ad,\n",
        "        p_tr_ad_edu, p_te_ad_edu,\n",
        "        'edu_bin',\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "res5_adult = pd.DataFrame(all_rows)\n",
        "print_block('STEP 5A — ADULT RAW (head)', res5_adult.head())\n",
        "print_block('ADULT Results shape', res5_adult.shape)\n",
        "\n",
        "summary5_adult = summarize_mean_std(res5_adult, group_cols=('dataset','protected_attr','method'))\n",
        "print_block('STEP 5A — ADULT MEAN ± STD', summary5_adult)\n",
        "\n",
        "metrics = ['accuracy', 'f1', 'auc', 'SPD', 'EOD', 'DI']\n",
        "methods_to_compare = ['Reweighing', 'Adversarial', 'ROC_post']\n",
        "\n",
        "pv_rows = []\n",
        "for (ds, attr), grp in res5_adult.groupby(['dataset','protected_attr']):\n",
        "    base = grp[grp['method'] == 'Baseline']\n",
        "    for m in methods_to_compare:\n",
        "        comp = grp[grp['method'] == m]\n",
        "        for metric in metrics:\n",
        "            base_vals = base[metric].values\n",
        "            comp_vals = comp[metric].values\n",
        "            if len(base_vals) == len(comp_vals) and len(base_vals) > 1:\n",
        "                pvals = paired_tests(base_vals, comp_vals)\n",
        "                pv_rows.append({\n",
        "                    'dataset': ds,\n",
        "                    'protected_attr': attr,\n",
        "                    'method_vs_baseline': m,\n",
        "                    'metric': metric,\n",
        "                    'ttest_p': pvals['ttest_p'],\n",
        "                    'wilcoxon_p': pvals['wilcoxon_p']\n",
        "                })\n",
        "\n",
        "pvals5_adult = pd.DataFrame(pv_rows)\n",
        "if not pvals5_adult.empty:\n",
        "    pvals5_adult['sig_ttest@0.05'] = pvals5_adult['ttest_p'] < 0.05\n",
        "    pvals5_adult['sig_wilcoxon@0.05'] = pvals5_adult['wilcoxon_p'] < 0.05\n",
        "\n",
        "print_block('STEP 5A — ADULT SIGNIFICANCE', pvals5_adult)\n",
        "\n",
        "# Save artifacts to disk\n",
        "res5_adult.to_csv('step5_adult_raw.csv', index=False)\n",
        "summary5_adult.to_csv('step5_adult_summary.csv', index=False)\n",
        "pvals5_adult.to_csv('step5_adult_pvals.csv', index=False)\n",
        "\n",
        "print('\\nSaved: step5_adult_raw.csv, step5_adult_summary.csv, step5_adult_pvals.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-8psuoS2bSV",
        "outputId": "41adcf3d-0e9f-4ec9-842c-24d49e943ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.742295; batch adversarial loss: 0.741474\n",
            "epoch 1; iter: 0; batch classifier loss: 0.347234; batch adversarial loss: 0.714793\n",
            "epoch 2; iter: 0; batch classifier loss: 0.305107; batch adversarial loss: 0.727259\n",
            "epoch 3; iter: 0; batch classifier loss: 0.288207; batch adversarial loss: 0.700075\n",
            "epoch 4; iter: 0; batch classifier loss: 0.325124; batch adversarial loss: 0.680498\n",
            "epoch 5; iter: 0; batch classifier loss: 0.320235; batch adversarial loss: 0.690856\n",
            "epoch 6; iter: 0; batch classifier loss: 0.356991; batch adversarial loss: 0.674536\n",
            "epoch 7; iter: 0; batch classifier loss: 0.336697; batch adversarial loss: 0.667821\n",
            "epoch 8; iter: 0; batch classifier loss: 0.318562; batch adversarial loss: 0.669220\n",
            "epoch 9; iter: 0; batch classifier loss: 0.380762; batch adversarial loss: 0.689869\n",
            "epoch 10; iter: 0; batch classifier loss: 0.405593; batch adversarial loss: 0.678475\n",
            "epoch 11; iter: 0; batch classifier loss: 0.331877; batch adversarial loss: 0.691435\n",
            "epoch 12; iter: 0; batch classifier loss: 0.345895; batch adversarial loss: 0.688403\n",
            "epoch 13; iter: 0; batch classifier loss: 0.387468; batch adversarial loss: 0.679491\n",
            "epoch 14; iter: 0; batch classifier loss: 0.340088; batch adversarial loss: 0.680181\n",
            "epoch 15; iter: 0; batch classifier loss: 0.386516; batch adversarial loss: 0.670319\n",
            "epoch 16; iter: 0; batch classifier loss: 0.311977; batch adversarial loss: 0.657381\n",
            "epoch 17; iter: 0; batch classifier loss: 0.331805; batch adversarial loss: 0.662799\n",
            "epoch 18; iter: 0; batch classifier loss: 0.310803; batch adversarial loss: 0.660151\n",
            "epoch 19; iter: 0; batch classifier loss: 0.312193; batch adversarial loss: 0.668826\n",
            "epoch 20; iter: 0; batch classifier loss: 0.379135; batch adversarial loss: 0.673546\n",
            "epoch 21; iter: 0; batch classifier loss: 0.298723; batch adversarial loss: 0.679986\n",
            "epoch 22; iter: 0; batch classifier loss: 0.365342; batch adversarial loss: 0.674309\n",
            "epoch 23; iter: 0; batch classifier loss: 0.291420; batch adversarial loss: 0.665555\n",
            "epoch 24; iter: 0; batch classifier loss: 0.329749; batch adversarial loss: 0.685197\n",
            "epoch 25; iter: 0; batch classifier loss: 0.306080; batch adversarial loss: 0.653100\n",
            "epoch 26; iter: 0; batch classifier loss: 0.367065; batch adversarial loss: 0.668207\n",
            "epoch 27; iter: 0; batch classifier loss: 0.394778; batch adversarial loss: 0.670432\n",
            "epoch 28; iter: 0; batch classifier loss: 0.349713; batch adversarial loss: 0.667708\n",
            "epoch 29; iter: 0; batch classifier loss: 0.401584; batch adversarial loss: 0.676091\n",
            "epoch 0; iter: 0; batch classifier loss: 0.740934; batch adversarial loss: 0.694945\n",
            "epoch 1; iter: 0; batch classifier loss: 0.359753; batch adversarial loss: 0.678787\n",
            "epoch 2; iter: 0; batch classifier loss: 0.300886; batch adversarial loss: 0.665004\n",
            "epoch 3; iter: 0; batch classifier loss: 0.294110; batch adversarial loss: 0.642769\n",
            "epoch 4; iter: 0; batch classifier loss: 0.325714; batch adversarial loss: 0.634272\n",
            "epoch 5; iter: 0; batch classifier loss: 0.323409; batch adversarial loss: 0.584852\n",
            "epoch 6; iter: 0; batch classifier loss: 0.355342; batch adversarial loss: 0.587572\n",
            "epoch 7; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.559186\n",
            "epoch 8; iter: 0; batch classifier loss: 0.303172; batch adversarial loss: 0.549618\n",
            "epoch 9; iter: 0; batch classifier loss: 0.351411; batch adversarial loss: 0.535327\n",
            "epoch 10; iter: 0; batch classifier loss: 0.350764; batch adversarial loss: 0.502521\n",
            "epoch 11; iter: 0; batch classifier loss: 0.308151; batch adversarial loss: 0.611228\n",
            "epoch 12; iter: 0; batch classifier loss: 0.292686; batch adversarial loss: 0.550146\n",
            "epoch 13; iter: 0; batch classifier loss: 0.341654; batch adversarial loss: 0.527553\n",
            "epoch 14; iter: 0; batch classifier loss: 0.300191; batch adversarial loss: 0.516772\n",
            "epoch 15; iter: 0; batch classifier loss: 0.359152; batch adversarial loss: 0.572517\n",
            "epoch 16; iter: 0; batch classifier loss: 0.304806; batch adversarial loss: 0.533634\n",
            "epoch 17; iter: 0; batch classifier loss: 0.324238; batch adversarial loss: 0.492593\n",
            "epoch 18; iter: 0; batch classifier loss: 0.306887; batch adversarial loss: 0.544253\n",
            "epoch 19; iter: 0; batch classifier loss: 0.328428; batch adversarial loss: 0.570361\n",
            "epoch 20; iter: 0; batch classifier loss: 0.358258; batch adversarial loss: 0.525554\n",
            "epoch 21; iter: 0; batch classifier loss: 0.301352; batch adversarial loss: 0.557591\n",
            "epoch 22; iter: 0; batch classifier loss: 0.342608; batch adversarial loss: 0.522780\n",
            "epoch 23; iter: 0; batch classifier loss: 0.278470; batch adversarial loss: 0.496450\n",
            "epoch 24; iter: 0; batch classifier loss: 0.333770; batch adversarial loss: 0.497813\n",
            "epoch 25; iter: 0; batch classifier loss: 0.302512; batch adversarial loss: 0.485009\n",
            "epoch 26; iter: 0; batch classifier loss: 0.342162; batch adversarial loss: 0.520328\n",
            "epoch 27; iter: 0; batch classifier loss: 0.378010; batch adversarial loss: 0.570512\n",
            "epoch 28; iter: 0; batch classifier loss: 0.343456; batch adversarial loss: 0.510498\n",
            "epoch 29; iter: 0; batch classifier loss: 0.405529; batch adversarial loss: 0.487230\n",
            "epoch 0; iter: 0; batch classifier loss: 0.810848; batch adversarial loss: 0.898496\n",
            "epoch 1; iter: 0; batch classifier loss: 0.850128; batch adversarial loss: 0.956177\n",
            "epoch 2; iter: 0; batch classifier loss: 0.842493; batch adversarial loss: 0.872901\n",
            "epoch 3; iter: 0; batch classifier loss: 0.817930; batch adversarial loss: 0.821923\n",
            "epoch 4; iter: 0; batch classifier loss: 0.715273; batch adversarial loss: 0.754820\n",
            "epoch 5; iter: 0; batch classifier loss: 0.505141; batch adversarial loss: 0.714221\n",
            "epoch 6; iter: 0; batch classifier loss: 0.458946; batch adversarial loss: 0.723940\n",
            "epoch 7; iter: 0; batch classifier loss: 0.494226; batch adversarial loss: 0.688341\n",
            "epoch 8; iter: 0; batch classifier loss: 0.476146; batch adversarial loss: 0.695633\n",
            "epoch 9; iter: 0; batch classifier loss: 0.426776; batch adversarial loss: 0.688293\n",
            "epoch 10; iter: 0; batch classifier loss: 0.312988; batch adversarial loss: 0.679213\n",
            "epoch 11; iter: 0; batch classifier loss: 0.286858; batch adversarial loss: 0.694187\n",
            "epoch 12; iter: 0; batch classifier loss: 0.322725; batch adversarial loss: 0.677069\n",
            "epoch 13; iter: 0; batch classifier loss: 0.315782; batch adversarial loss: 0.680510\n",
            "epoch 14; iter: 0; batch classifier loss: 0.371198; batch adversarial loss: 0.667459\n",
            "epoch 15; iter: 0; batch classifier loss: 0.337803; batch adversarial loss: 0.675719\n",
            "epoch 16; iter: 0; batch classifier loss: 0.336490; batch adversarial loss: 0.685671\n",
            "epoch 17; iter: 0; batch classifier loss: 0.277795; batch adversarial loss: 0.691821\n",
            "epoch 18; iter: 0; batch classifier loss: 0.339574; batch adversarial loss: 0.671283\n",
            "epoch 19; iter: 0; batch classifier loss: 0.343588; batch adversarial loss: 0.669096\n",
            "epoch 20; iter: 0; batch classifier loss: 0.369414; batch adversarial loss: 0.684276\n",
            "epoch 21; iter: 0; batch classifier loss: 0.382067; batch adversarial loss: 0.668664\n",
            "epoch 22; iter: 0; batch classifier loss: 0.309371; batch adversarial loss: 0.693587\n",
            "epoch 23; iter: 0; batch classifier loss: 0.330110; batch adversarial loss: 0.657340\n",
            "epoch 24; iter: 0; batch classifier loss: 0.292848; batch adversarial loss: 0.664207\n",
            "epoch 25; iter: 0; batch classifier loss: 0.260256; batch adversarial loss: 0.649452\n",
            "epoch 26; iter: 0; batch classifier loss: 0.255799; batch adversarial loss: 0.674182\n",
            "epoch 27; iter: 0; batch classifier loss: 0.288576; batch adversarial loss: 0.646621\n",
            "epoch 28; iter: 0; batch classifier loss: 0.283212; batch adversarial loss: 0.638825\n",
            "epoch 29; iter: 0; batch classifier loss: 0.282472; batch adversarial loss: 0.670203\n",
            "epoch 0; iter: 0; batch classifier loss: 0.806022; batch adversarial loss: 1.031172\n",
            "epoch 1; iter: 0; batch classifier loss: 1.220658; batch adversarial loss: 1.120808\n",
            "epoch 2; iter: 0; batch classifier loss: 1.159720; batch adversarial loss: 0.943639\n",
            "epoch 3; iter: 0; batch classifier loss: 1.075566; batch adversarial loss: 0.840379\n",
            "epoch 4; iter: 0; batch classifier loss: 0.899934; batch adversarial loss: 0.730027\n",
            "epoch 5; iter: 0; batch classifier loss: 0.626262; batch adversarial loss: 0.654019\n",
            "epoch 6; iter: 0; batch classifier loss: 0.536068; batch adversarial loss: 0.643096\n",
            "epoch 7; iter: 0; batch classifier loss: 0.474968; batch adversarial loss: 0.577520\n",
            "epoch 8; iter: 0; batch classifier loss: 0.367257; batch adversarial loss: 0.603202\n",
            "epoch 9; iter: 0; batch classifier loss: 0.372020; batch adversarial loss: 0.601688\n",
            "epoch 10; iter: 0; batch classifier loss: 0.304817; batch adversarial loss: 0.562171\n",
            "epoch 11; iter: 0; batch classifier loss: 0.286516; batch adversarial loss: 0.570608\n",
            "epoch 12; iter: 0; batch classifier loss: 0.339778; batch adversarial loss: 0.561958\n",
            "epoch 13; iter: 0; batch classifier loss: 0.351605; batch adversarial loss: 0.597076\n",
            "epoch 14; iter: 0; batch classifier loss: 0.394903; batch adversarial loss: 0.537005\n",
            "epoch 15; iter: 0; batch classifier loss: 0.329173; batch adversarial loss: 0.522715\n",
            "epoch 16; iter: 0; batch classifier loss: 0.351621; batch adversarial loss: 0.525573\n",
            "epoch 17; iter: 0; batch classifier loss: 0.296608; batch adversarial loss: 0.528984\n",
            "epoch 18; iter: 0; batch classifier loss: 0.340454; batch adversarial loss: 0.531650\n",
            "epoch 19; iter: 0; batch classifier loss: 0.343301; batch adversarial loss: 0.503230\n",
            "epoch 20; iter: 0; batch classifier loss: 0.385414; batch adversarial loss: 0.534496\n",
            "epoch 21; iter: 0; batch classifier loss: 0.364241; batch adversarial loss: 0.500291\n",
            "epoch 22; iter: 0; batch classifier loss: 0.301367; batch adversarial loss: 0.529956\n",
            "epoch 23; iter: 0; batch classifier loss: 0.312366; batch adversarial loss: 0.499443\n",
            "epoch 24; iter: 0; batch classifier loss: 0.274141; batch adversarial loss: 0.487253\n",
            "epoch 25; iter: 0; batch classifier loss: 0.245633; batch adversarial loss: 0.513041\n",
            "epoch 26; iter: 0; batch classifier loss: 0.249754; batch adversarial loss: 0.575452\n",
            "epoch 27; iter: 0; batch classifier loss: 0.274909; batch adversarial loss: 0.545576\n",
            "epoch 28; iter: 0; batch classifier loss: 0.289540; batch adversarial loss: 0.474260\n",
            "epoch 29; iter: 0; batch classifier loss: 0.282573; batch adversarial loss: 0.507895\n",
            "epoch 0; iter: 0; batch classifier loss: 0.701271; batch adversarial loss: 0.661239\n",
            "epoch 1; iter: 0; batch classifier loss: 0.300395; batch adversarial loss: 0.706499\n",
            "epoch 2; iter: 0; batch classifier loss: 0.358241; batch adversarial loss: 0.750067\n",
            "epoch 3; iter: 0; batch classifier loss: 0.393458; batch adversarial loss: 0.739195\n",
            "epoch 4; iter: 0; batch classifier loss: 0.389666; batch adversarial loss: 0.714899\n",
            "epoch 5; iter: 0; batch classifier loss: 0.321941; batch adversarial loss: 0.686312\n",
            "epoch 6; iter: 0; batch classifier loss: 0.279049; batch adversarial loss: 0.680383\n",
            "epoch 7; iter: 0; batch classifier loss: 0.330083; batch adversarial loss: 0.668339\n",
            "epoch 8; iter: 0; batch classifier loss: 0.283023; batch adversarial loss: 0.660548\n",
            "epoch 9; iter: 0; batch classifier loss: 0.348220; batch adversarial loss: 0.671031\n",
            "epoch 10; iter: 0; batch classifier loss: 0.318486; batch adversarial loss: 0.655587\n",
            "epoch 11; iter: 0; batch classifier loss: 0.344107; batch adversarial loss: 0.675677\n",
            "epoch 12; iter: 0; batch classifier loss: 0.287972; batch adversarial loss: 0.630493\n",
            "epoch 13; iter: 0; batch classifier loss: 0.321819; batch adversarial loss: 0.643538\n",
            "epoch 14; iter: 0; batch classifier loss: 0.291915; batch adversarial loss: 0.666384\n",
            "epoch 15; iter: 0; batch classifier loss: 0.279453; batch adversarial loss: 0.661787\n",
            "epoch 16; iter: 0; batch classifier loss: 0.289257; batch adversarial loss: 0.682077\n",
            "epoch 17; iter: 0; batch classifier loss: 0.328597; batch adversarial loss: 0.649605\n",
            "epoch 18; iter: 0; batch classifier loss: 0.277192; batch adversarial loss: 0.677509\n",
            "epoch 19; iter: 0; batch classifier loss: 0.326977; batch adversarial loss: 0.646153\n",
            "epoch 20; iter: 0; batch classifier loss: 0.260019; batch adversarial loss: 0.624823\n",
            "epoch 21; iter: 0; batch classifier loss: 0.235512; batch adversarial loss: 0.648802\n",
            "epoch 22; iter: 0; batch classifier loss: 0.302411; batch adversarial loss: 0.664205\n",
            "epoch 23; iter: 0; batch classifier loss: 0.241580; batch adversarial loss: 0.663203\n",
            "epoch 24; iter: 0; batch classifier loss: 0.303869; batch adversarial loss: 0.645057\n",
            "epoch 25; iter: 0; batch classifier loss: 0.331468; batch adversarial loss: 0.675263\n",
            "epoch 26; iter: 0; batch classifier loss: 0.308757; batch adversarial loss: 0.652401\n",
            "epoch 27; iter: 0; batch classifier loss: 0.268646; batch adversarial loss: 0.691629\n",
            "epoch 28; iter: 0; batch classifier loss: 0.303826; batch adversarial loss: 0.671025\n",
            "epoch 29; iter: 0; batch classifier loss: 0.300853; batch adversarial loss: 0.664390\n",
            "epoch 0; iter: 0; batch classifier loss: 0.694635; batch adversarial loss: 0.578419\n",
            "epoch 1; iter: 0; batch classifier loss: 0.301188; batch adversarial loss: 0.641189\n",
            "epoch 2; iter: 0; batch classifier loss: 0.295502; batch adversarial loss: 0.653356\n",
            "epoch 3; iter: 0; batch classifier loss: 0.281868; batch adversarial loss: 0.650354\n",
            "epoch 4; iter: 0; batch classifier loss: 0.306482; batch adversarial loss: 0.579215\n",
            "epoch 5; iter: 0; batch classifier loss: 0.311564; batch adversarial loss: 0.585866\n",
            "epoch 6; iter: 0; batch classifier loss: 0.274865; batch adversarial loss: 0.537462\n",
            "epoch 7; iter: 0; batch classifier loss: 0.320693; batch adversarial loss: 0.507793\n",
            "epoch 8; iter: 0; batch classifier loss: 0.283964; batch adversarial loss: 0.550362\n",
            "epoch 9; iter: 0; batch classifier loss: 0.345449; batch adversarial loss: 0.520617\n",
            "epoch 10; iter: 0; batch classifier loss: 0.313694; batch adversarial loss: 0.494206\n",
            "epoch 11; iter: 0; batch classifier loss: 0.342491; batch adversarial loss: 0.517660\n",
            "epoch 12; iter: 0; batch classifier loss: 0.284065; batch adversarial loss: 0.522315\n",
            "epoch 13; iter: 0; batch classifier loss: 0.319979; batch adversarial loss: 0.478117\n",
            "epoch 14; iter: 0; batch classifier loss: 0.293551; batch adversarial loss: 0.453016\n",
            "epoch 15; iter: 0; batch classifier loss: 0.290032; batch adversarial loss: 0.447102\n",
            "epoch 16; iter: 0; batch classifier loss: 0.285710; batch adversarial loss: 0.445028\n",
            "epoch 17; iter: 0; batch classifier loss: 0.326932; batch adversarial loss: 0.453941\n",
            "epoch 18; iter: 0; batch classifier loss: 0.282903; batch adversarial loss: 0.468000\n",
            "epoch 19; iter: 0; batch classifier loss: 0.321153; batch adversarial loss: 0.496394\n",
            "epoch 20; iter: 0; batch classifier loss: 0.257625; batch adversarial loss: 0.557234\n",
            "epoch 21; iter: 0; batch classifier loss: 0.243002; batch adversarial loss: 0.503836\n",
            "epoch 22; iter: 0; batch classifier loss: 0.291937; batch adversarial loss: 0.488359\n",
            "epoch 23; iter: 0; batch classifier loss: 0.245843; batch adversarial loss: 0.515724\n",
            "epoch 24; iter: 0; batch classifier loss: 0.304548; batch adversarial loss: 0.534168\n",
            "epoch 25; iter: 0; batch classifier loss: 0.346274; batch adversarial loss: 0.514435\n",
            "epoch 26; iter: 0; batch classifier loss: 0.336319; batch adversarial loss: 0.483872\n",
            "epoch 27; iter: 0; batch classifier loss: 0.291338; batch adversarial loss: 0.563250\n",
            "epoch 28; iter: 0; batch classifier loss: 0.306409; batch adversarial loss: 0.490968\n",
            "epoch 29; iter: 0; batch classifier loss: 0.277744; batch adversarial loss: 0.502615\n",
            "epoch 0; iter: 0; batch classifier loss: 0.728230; batch adversarial loss: 0.855715\n",
            "epoch 1; iter: 0; batch classifier loss: 0.801017; batch adversarial loss: 0.901276\n",
            "epoch 2; iter: 0; batch classifier loss: 0.779121; batch adversarial loss: 0.830976\n",
            "epoch 3; iter: 0; batch classifier loss: 0.633941; batch adversarial loss: 0.789455\n",
            "epoch 4; iter: 0; batch classifier loss: 0.433093; batch adversarial loss: 0.719651\n",
            "epoch 5; iter: 0; batch classifier loss: 0.296874; batch adversarial loss: 0.685192\n",
            "epoch 6; iter: 0; batch classifier loss: 0.348389; batch adversarial loss: 0.684746\n",
            "epoch 7; iter: 0; batch classifier loss: 0.270700; batch adversarial loss: 0.680494\n",
            "epoch 8; iter: 0; batch classifier loss: 0.298361; batch adversarial loss: 0.673275\n",
            "epoch 9; iter: 0; batch classifier loss: 0.355052; batch adversarial loss: 0.677697\n",
            "epoch 10; iter: 0; batch classifier loss: 0.285033; batch adversarial loss: 0.659526\n",
            "epoch 11; iter: 0; batch classifier loss: 0.273804; batch adversarial loss: 0.680026\n",
            "epoch 12; iter: 0; batch classifier loss: 0.306093; batch adversarial loss: 0.696290\n",
            "epoch 13; iter: 0; batch classifier loss: 0.318801; batch adversarial loss: 0.673778\n",
            "epoch 14; iter: 0; batch classifier loss: 0.275132; batch adversarial loss: 0.683121\n",
            "epoch 15; iter: 0; batch classifier loss: 0.342579; batch adversarial loss: 0.688124\n",
            "epoch 16; iter: 0; batch classifier loss: 0.383595; batch adversarial loss: 0.687944\n",
            "epoch 17; iter: 0; batch classifier loss: 0.436840; batch adversarial loss: 0.703007\n",
            "epoch 18; iter: 0; batch classifier loss: 0.430142; batch adversarial loss: 0.693925\n",
            "epoch 19; iter: 0; batch classifier loss: 0.434037; batch adversarial loss: 0.704380\n",
            "epoch 20; iter: 0; batch classifier loss: 0.348596; batch adversarial loss: 0.662259\n",
            "epoch 21; iter: 0; batch classifier loss: 0.287957; batch adversarial loss: 0.660364\n",
            "epoch 22; iter: 0; batch classifier loss: 0.329639; batch adversarial loss: 0.673346\n",
            "epoch 23; iter: 0; batch classifier loss: 0.354253; batch adversarial loss: 0.689501\n",
            "epoch 24; iter: 0; batch classifier loss: 0.319881; batch adversarial loss: 0.661865\n",
            "epoch 25; iter: 0; batch classifier loss: 0.264875; batch adversarial loss: 0.677974\n",
            "epoch 26; iter: 0; batch classifier loss: 0.379295; batch adversarial loss: 0.700297\n",
            "epoch 27; iter: 0; batch classifier loss: 0.319371; batch adversarial loss: 0.673863\n",
            "epoch 28; iter: 0; batch classifier loss: 0.331358; batch adversarial loss: 0.678692\n",
            "epoch 29; iter: 0; batch classifier loss: 0.306257; batch adversarial loss: 0.655657\n",
            "epoch 0; iter: 0; batch classifier loss: 0.729136; batch adversarial loss: 0.941703\n",
            "epoch 1; iter: 0; batch classifier loss: 1.130092; batch adversarial loss: 1.035291\n",
            "epoch 2; iter: 0; batch classifier loss: 1.016429; batch adversarial loss: 0.881799\n",
            "epoch 3; iter: 0; batch classifier loss: 0.865247; batch adversarial loss: 0.787374\n",
            "epoch 4; iter: 0; batch classifier loss: 0.677421; batch adversarial loss: 0.695538\n",
            "epoch 5; iter: 0; batch classifier loss: 0.478980; batch adversarial loss: 0.636054\n",
            "epoch 6; iter: 0; batch classifier loss: 0.376324; batch adversarial loss: 0.617148\n",
            "epoch 7; iter: 0; batch classifier loss: 0.272103; batch adversarial loss: 0.574391\n",
            "epoch 8; iter: 0; batch classifier loss: 0.319202; batch adversarial loss: 0.587358\n",
            "epoch 9; iter: 0; batch classifier loss: 0.357016; batch adversarial loss: 0.585782\n",
            "epoch 10; iter: 0; batch classifier loss: 0.291508; batch adversarial loss: 0.546972\n",
            "epoch 11; iter: 0; batch classifier loss: 0.289810; batch adversarial loss: 0.550303\n",
            "epoch 12; iter: 0; batch classifier loss: 0.296121; batch adversarial loss: 0.566030\n",
            "epoch 13; iter: 0; batch classifier loss: 0.318331; batch adversarial loss: 0.515413\n",
            "epoch 14; iter: 0; batch classifier loss: 0.247500; batch adversarial loss: 0.491625\n",
            "epoch 15; iter: 0; batch classifier loss: 0.271334; batch adversarial loss: 0.567094\n",
            "epoch 16; iter: 0; batch classifier loss: 0.294676; batch adversarial loss: 0.534659\n",
            "epoch 17; iter: 0; batch classifier loss: 0.362329; batch adversarial loss: 0.612957\n",
            "epoch 18; iter: 0; batch classifier loss: 0.344373; batch adversarial loss: 0.515020\n",
            "epoch 19; iter: 0; batch classifier loss: 0.356468; batch adversarial loss: 0.543498\n",
            "epoch 20; iter: 0; batch classifier loss: 0.310125; batch adversarial loss: 0.508127\n",
            "epoch 21; iter: 0; batch classifier loss: 0.282632; batch adversarial loss: 0.505503\n",
            "epoch 22; iter: 0; batch classifier loss: 0.335489; batch adversarial loss: 0.536130\n",
            "epoch 23; iter: 0; batch classifier loss: 0.372726; batch adversarial loss: 0.520802\n",
            "epoch 24; iter: 0; batch classifier loss: 0.332011; batch adversarial loss: 0.529201\n",
            "epoch 25; iter: 0; batch classifier loss: 0.248650; batch adversarial loss: 0.515787\n",
            "epoch 26; iter: 0; batch classifier loss: 0.379547; batch adversarial loss: 0.535613\n",
            "epoch 27; iter: 0; batch classifier loss: 0.318782; batch adversarial loss: 0.480064\n",
            "epoch 28; iter: 0; batch classifier loss: 0.331320; batch adversarial loss: 0.481633\n",
            "epoch 29; iter: 0; batch classifier loss: 0.283754; batch adversarial loss: 0.508738\n",
            "epoch 0; iter: 0; batch classifier loss: 0.761286; batch adversarial loss: 0.660853\n",
            "epoch 1; iter: 0; batch classifier loss: 0.321930; batch adversarial loss: 0.710958\n",
            "epoch 2; iter: 0; batch classifier loss: 0.260661; batch adversarial loss: 0.693593\n",
            "epoch 3; iter: 0; batch classifier loss: 0.329808; batch adversarial loss: 0.668392\n",
            "epoch 4; iter: 0; batch classifier loss: 0.316129; batch adversarial loss: 0.683999\n",
            "epoch 5; iter: 0; batch classifier loss: 0.327882; batch adversarial loss: 0.673609\n",
            "epoch 6; iter: 0; batch classifier loss: 0.296711; batch adversarial loss: 0.661833\n",
            "epoch 7; iter: 0; batch classifier loss: 0.308545; batch adversarial loss: 0.663497\n",
            "epoch 8; iter: 0; batch classifier loss: 0.333768; batch adversarial loss: 0.660913\n",
            "epoch 9; iter: 0; batch classifier loss: 0.357375; batch adversarial loss: 0.679417\n",
            "epoch 10; iter: 0; batch classifier loss: 0.288278; batch adversarial loss: 0.690448\n",
            "epoch 11; iter: 0; batch classifier loss: 0.291443; batch adversarial loss: 0.675228\n",
            "epoch 12; iter: 0; batch classifier loss: 0.307841; batch adversarial loss: 0.675701\n",
            "epoch 13; iter: 0; batch classifier loss: 0.330137; batch adversarial loss: 0.663991\n",
            "epoch 14; iter: 0; batch classifier loss: 0.301168; batch adversarial loss: 0.665959\n",
            "epoch 15; iter: 0; batch classifier loss: 0.332185; batch adversarial loss: 0.666212\n",
            "epoch 16; iter: 0; batch classifier loss: 0.323594; batch adversarial loss: 0.673005\n",
            "epoch 17; iter: 0; batch classifier loss: 0.313993; batch adversarial loss: 0.664574\n",
            "epoch 18; iter: 0; batch classifier loss: 0.310397; batch adversarial loss: 0.671607\n",
            "epoch 19; iter: 0; batch classifier loss: 0.341941; batch adversarial loss: 0.684018\n",
            "epoch 20; iter: 0; batch classifier loss: 0.285678; batch adversarial loss: 0.699476\n",
            "epoch 21; iter: 0; batch classifier loss: 0.408341; batch adversarial loss: 0.677778\n",
            "epoch 22; iter: 0; batch classifier loss: 0.353660; batch adversarial loss: 0.689241\n",
            "epoch 23; iter: 0; batch classifier loss: 0.311531; batch adversarial loss: 0.676323\n",
            "epoch 24; iter: 0; batch classifier loss: 0.277638; batch adversarial loss: 0.670721\n",
            "epoch 25; iter: 0; batch classifier loss: 0.293315; batch adversarial loss: 0.667323\n",
            "epoch 26; iter: 0; batch classifier loss: 0.367080; batch adversarial loss: 0.665722\n",
            "epoch 27; iter: 0; batch classifier loss: 0.321090; batch adversarial loss: 0.668621\n",
            "epoch 28; iter: 0; batch classifier loss: 0.280489; batch adversarial loss: 0.690036\n",
            "epoch 29; iter: 0; batch classifier loss: 0.325027; batch adversarial loss: 0.648653\n",
            "epoch 0; iter: 0; batch classifier loss: 0.764244; batch adversarial loss: 0.604145\n",
            "epoch 1; iter: 0; batch classifier loss: 0.358417; batch adversarial loss: 0.653116\n",
            "epoch 2; iter: 0; batch classifier loss: 0.266169; batch adversarial loss: 0.647183\n",
            "epoch 3; iter: 0; batch classifier loss: 0.327295; batch adversarial loss: 0.633637\n",
            "epoch 4; iter: 0; batch classifier loss: 0.312597; batch adversarial loss: 0.571956\n",
            "epoch 5; iter: 0; batch classifier loss: 0.335895; batch adversarial loss: 0.582414\n",
            "epoch 6; iter: 0; batch classifier loss: 0.293975; batch adversarial loss: 0.561063\n",
            "epoch 7; iter: 0; batch classifier loss: 0.306817; batch adversarial loss: 0.558046\n",
            "epoch 8; iter: 0; batch classifier loss: 0.319933; batch adversarial loss: 0.528757\n",
            "epoch 9; iter: 0; batch classifier loss: 0.355504; batch adversarial loss: 0.506430\n",
            "epoch 10; iter: 0; batch classifier loss: 0.267766; batch adversarial loss: 0.497361\n",
            "epoch 11; iter: 0; batch classifier loss: 0.264650; batch adversarial loss: 0.518613\n",
            "epoch 12; iter: 0; batch classifier loss: 0.301698; batch adversarial loss: 0.460010\n",
            "epoch 13; iter: 0; batch classifier loss: 0.285834; batch adversarial loss: 0.514324\n",
            "epoch 14; iter: 0; batch classifier loss: 0.269588; batch adversarial loss: 0.489518\n",
            "epoch 15; iter: 0; batch classifier loss: 0.311608; batch adversarial loss: 0.490629\n",
            "epoch 16; iter: 0; batch classifier loss: 0.301738; batch adversarial loss: 0.504902\n",
            "epoch 17; iter: 0; batch classifier loss: 0.284593; batch adversarial loss: 0.495835\n",
            "epoch 18; iter: 0; batch classifier loss: 0.307516; batch adversarial loss: 0.541853\n",
            "epoch 19; iter: 0; batch classifier loss: 0.352885; batch adversarial loss: 0.535463\n",
            "epoch 20; iter: 0; batch classifier loss: 0.257332; batch adversarial loss: 0.507916\n",
            "epoch 21; iter: 0; batch classifier loss: 0.386670; batch adversarial loss: 0.485454\n",
            "epoch 22; iter: 0; batch classifier loss: 0.337045; batch adversarial loss: 0.534035\n",
            "epoch 23; iter: 0; batch classifier loss: 0.294455; batch adversarial loss: 0.529605\n",
            "epoch 24; iter: 0; batch classifier loss: 0.275858; batch adversarial loss: 0.537987\n",
            "epoch 25; iter: 0; batch classifier loss: 0.303111; batch adversarial loss: 0.522679\n",
            "epoch 26; iter: 0; batch classifier loss: 0.359681; batch adversarial loss: 0.520512\n",
            "epoch 27; iter: 0; batch classifier loss: 0.300265; batch adversarial loss: 0.548084\n",
            "epoch 28; iter: 0; batch classifier loss: 0.301267; batch adversarial loss: 0.494378\n",
            "epoch 29; iter: 0; batch classifier loss: 0.317200; batch adversarial loss: 0.475628\n",
            "\n",
            "====================================================================================================\n",
            "STEP 5A — ADULT RAW (head)\n",
            "====================================================================================================\n",
            "  dataset protected_attr       method  accuracy        f1       auc       SPD  \\\n",
            "0   Adult        age_bin     Baseline  0.852925  0.657989  0.905339 -0.185882   \n",
            "1   Adult        age_bin   Reweighing  0.850772  0.646459  0.899566 -0.114940   \n",
            "2   Adult        age_bin  Adversarial  0.846774  0.617534  0.903972 -0.040966   \n",
            "3   Adult        age_bin     ROC_post  0.777573  0.635851  0.905339 -0.018674   \n",
            "4   Adult        edu_bin     Baseline  0.852925  0.657989  0.905339 -0.434152   \n",
            "\n",
            "        EOD        DI  \n",
            "0 -0.128992  0.375711  \n",
            "1 -0.000812  0.540433  \n",
            "2  0.154589  0.781201  \n",
            "3  0.176346  0.951488  \n",
            "4 -0.479127  0.165204  \n",
            "\n",
            "====================================================================================================\n",
            "ADULT Results shape\n",
            "====================================================================================================\n",
            "(40, 9)\n",
            "\n",
            "====================================================================================================\n",
            "STEP 5A — ADULT MEAN ± STD\n",
            "====================================================================================================\n",
            "  dataset protected_attr       method  accuracy_mean  accuracy_std   f1_mean  \\\n",
            "0   Adult        age_bin  Adversarial       0.846614      0.002007  0.623245   \n",
            "1   Adult        age_bin     Baseline       0.852925      0.000000  0.657989   \n",
            "2   Adult        age_bin     ROC_post       0.777573      0.000000  0.635851   \n",
            "3   Adult        age_bin   Reweighing       0.850772      0.000000  0.646459   \n",
            "4   Adult        edu_bin  Adversarial       0.845986      0.003161  0.637493   \n",
            "5   Adult        edu_bin     Baseline       0.852925      0.000000  0.657989   \n",
            "6   Adult        edu_bin     ROC_post       0.764286      0.000000  0.611043   \n",
            "7   Adult        edu_bin   Reweighing       0.831088      0.000000  0.596651   \n",
            "\n",
            "     f1_std  auc_mean   auc_std  SPD_mean  SPD_std  EOD_mean   EOD_std  \\\n",
            "0  0.007635  0.904100  0.001217 -0.045826  0.01395  0.143788  0.026934   \n",
            "1  0.000000  0.905339  0.000000 -0.185882  0.00000 -0.128992  0.000000   \n",
            "2  0.000000  0.905339  0.000000 -0.018674  0.00000  0.176346  0.000000   \n",
            "3  0.000000  0.899566  0.000000 -0.114940  0.00000 -0.000812  0.000000   \n",
            "4  0.011593  0.904013  0.001854 -0.213935  0.03421 -0.108573  0.054894   \n",
            "5  0.000000  0.905339  0.000000 -0.434152  0.00000 -0.479127  0.000000   \n",
            "6  0.000000  0.905339  0.000000 -0.019757  0.00000  0.227597  0.000000   \n",
            "7  0.000000  0.884159  0.000000 -0.125792  0.00000  0.025151  0.000000   \n",
            "\n",
            "    DI_mean    DI_std  runs  \n",
            "0  0.769118  0.058331     5  \n",
            "1  0.375711  0.000000     5  \n",
            "2  0.951488  0.000000     5  \n",
            "3  0.540433  0.000000     5  \n",
            "4  0.390692  0.042230     5  \n",
            "5  0.165204  0.000000     5  \n",
            "6  0.948621  0.000000     5  \n",
            "7  0.545889  0.000000     5  \n",
            "\n",
            "====================================================================================================\n",
            "STEP 5A — ADULT SIGNIFICANCE\n",
            "====================================================================================================\n",
            "   dataset protected_attr method_vs_baseline    metric   ttest_p  wilcoxon_p  \\\n",
            "0    Adult        age_bin         Reweighing  accuracy  0.000000      0.0625   \n",
            "1    Adult        age_bin         Reweighing        f1  0.000000      0.0625   \n",
            "2    Adult        age_bin         Reweighing       auc  0.000000      0.0625   \n",
            "3    Adult        age_bin         Reweighing       SPD  0.000000      0.0625   \n",
            "4    Adult        age_bin         Reweighing       EOD  0.000000      0.0625   \n",
            "5    Adult        age_bin         Reweighing        DI  0.000000      0.0625   \n",
            "6    Adult        age_bin        Adversarial  accuracy  0.002156      0.0625   \n",
            "7    Adult        age_bin        Adversarial        f1  0.000525      0.0625   \n",
            "8    Adult        age_bin        Adversarial       auc  0.085162      0.1250   \n",
            "9    Adult        age_bin        Adversarial       SPD  0.000023      0.0625   \n",
            "10   Adult        age_bin        Adversarial       EOD  0.000023      0.0625   \n",
            "11   Adult        age_bin        Adversarial        DI  0.000113      0.0625   \n",
            "12   Adult        age_bin           ROC_post  accuracy  0.000000      0.0625   \n",
            "13   Adult        age_bin           ROC_post        f1  0.000000      0.0625   \n",
            "14   Adult        age_bin           ROC_post       auc       NaN         NaN   \n",
            "15   Adult        age_bin           ROC_post       SPD  0.000000      0.0625   \n",
            "16   Adult        age_bin           ROC_post       EOD  0.000000      0.0625   \n",
            "17   Adult        age_bin           ROC_post        DI  0.000000      0.0625   \n",
            "18   Adult        edu_bin         Reweighing  accuracy  0.000000      0.0625   \n",
            "19   Adult        edu_bin         Reweighing        f1  0.000000      0.0625   \n",
            "20   Adult        edu_bin         Reweighing       auc  0.000000      0.0625   \n",
            "21   Adult        edu_bin         Reweighing       SPD  0.000000      0.0625   \n",
            "22   Adult        edu_bin         Reweighing       EOD  0.000000      0.0625   \n",
            "23   Adult        edu_bin         Reweighing        DI  0.000000      0.0625   \n",
            "24   Adult        edu_bin        Adversarial  accuracy  0.007996      0.0625   \n",
            "25   Adult        edu_bin        Adversarial        f1  0.016771      0.0625   \n",
            "26   Adult        edu_bin        Adversarial       auc  0.184934      0.3125   \n",
            "27   Adult        edu_bin        Adversarial       SPD  0.000135      0.0625   \n",
            "28   Adult        edu_bin        Adversarial       EOD  0.000112      0.0625   \n",
            "29   Adult        edu_bin        Adversarial        DI  0.000282      0.0625   \n",
            "30   Adult        edu_bin           ROC_post  accuracy  0.000000      0.0625   \n",
            "31   Adult        edu_bin           ROC_post        f1  0.000000      0.0625   \n",
            "32   Adult        edu_bin           ROC_post       auc       NaN         NaN   \n",
            "33   Adult        edu_bin           ROC_post       SPD  0.000000      0.0625   \n",
            "34   Adult        edu_bin           ROC_post       EOD  0.000000      0.0625   \n",
            "35   Adult        edu_bin           ROC_post        DI  0.000000      0.0625   \n",
            "\n",
            "    sig_ttest@0.05  sig_wilcoxon@0.05  \n",
            "0             True              False  \n",
            "1             True              False  \n",
            "2             True              False  \n",
            "3             True              False  \n",
            "4             True              False  \n",
            "5             True              False  \n",
            "6             True              False  \n",
            "7             True              False  \n",
            "8            False              False  \n",
            "9             True              False  \n",
            "10            True              False  \n",
            "11            True              False  \n",
            "12            True              False  \n",
            "13            True              False  \n",
            "14           False              False  \n",
            "15            True              False  \n",
            "16            True              False  \n",
            "17            True              False  \n",
            "18            True              False  \n",
            "19            True              False  \n",
            "20            True              False  \n",
            "21            True              False  \n",
            "22            True              False  \n",
            "23            True              False  \n",
            "24            True              False  \n",
            "25            True              False  \n",
            "26           False              False  \n",
            "27            True              False  \n",
            "28            True              False  \n",
            "29            True              False  \n",
            "30            True              False  \n",
            "31            True              False  \n",
            "32           False              False  \n",
            "33            True              False  \n",
            "34            True              False  \n",
            "35            True              False  \n",
            "\n",
            "Saved: step5_adult_raw.csv, step5_adult_summary.csv, step5_adult_pvals.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ls -lh *.csv\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"step5_adult_raw.csv\")\n",
        "files.download(\"step5_adult_summary.csv\")\n",
        "files.download(\"step5_adult_pvals.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "mB-ivS-0KsZx",
        "outputId": "c068f18d-c0b9-4ed4-f072-71b704019e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 1.7M Aug 10 17:15 adult_test.csv\n",
            "-rw-r--r-- 1 root root 3.4M Aug 10 17:15 adult_train.csv\n",
            "-rw-r--r-- 1 root root  63K Aug 10 17:15 recruitment_data.csv\n",
            "-rw-r--r-- 1 root root 2.1K Aug 10 18:08 step5_adult_pvals.csv\n",
            "-rw-r--r-- 1 root root 5.6K Aug 10 18:08 step5_adult_raw.csv\n",
            "-rw-r--r-- 1 root root 1.7K Aug 10 18:08 step5_adult_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e7c52c46-1b8b-469c-9184-8d0f1a3752ce\", \"step5_adult_raw.csv\", 5703)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_efe9a6b6-148c-4c99-91f2-15cf1026b6ac\", \"step5_adult_summary.csv\", 1682)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0175baa2-fc17-4b31-b7f9-487db759d815\", \"step5_adult_pvals.csv\", 2139)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5B (Kaggle): Repeated runs + significance tests vs Baseline\n",
        "\n",
        "\n",
        "\n",
        "import gc\n",
        "\n",
        "\n",
        "\n",
        "def paired_tests(scores_a, scores_b):\n",
        "    a = np.array(scores_a, dtype=float)\n",
        "    b = np.array(scores_b, dtype=float)\n",
        "    t_p = stats.ttest_rel(a, b, alternative='two-sided').pvalue\n",
        "    try:\n",
        "        w_p = stats.wilcoxon(a, b, alternative='two-sided', zero_method='wilcox').pvalue\n",
        "    except Exception:\n",
        "        w_p = np.nan\n",
        "    return dict(ttest_p=t_p, wilcoxon_p=w_p)\n",
        "\n",
        "def summarize_mean_std(df, group_cols=('dataset','protected_attr','method')):\n",
        "    agg = df.groupby(list(group_cols)).agg(\n",
        "        accuracy_mean=('accuracy','mean'), accuracy_std=('accuracy','std'),\n",
        "        f1_mean=('f1','mean'), f1_std=('f1','std'),\n",
        "        auc_mean=('auc','mean'), auc_std=('auc','std'),\n",
        "        SPD_mean=('SPD','mean'), SPD_std=('SPD','std'),\n",
        "        EOD_mean=('EOD','mean'), EOD_std=('EOD','std'),\n",
        "        DI_mean=('DI','mean'), DI_std=('DI','std'),\n",
        "        runs=('accuracy','count')\n",
        "    ).reset_index()\n",
        "    return agg\n",
        "\n",
        "def print_block(title, obj):\n",
        "    print('\\n' + '='*100)\n",
        "    print(title)\n",
        "    print('='*100)\n",
        "    print(obj)\n",
        "\n",
        "# Local runners\n",
        "\n",
        "def s5_run_baseline(X_tr, y_tr, X_te, y_te, prot_te, prot_name, seed=42):\n",
        "    clf = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    y_score = clf.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_pred = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te_true, bld_te_pred, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_reweighing(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    rw = Reweighing(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}]\n",
        "    )\n",
        "    bld_tr_rw = rw.fit_transform(bld_tr)\n",
        "    sample_w = bld_tr_rw.instance_weights\n",
        "\n",
        "    clf = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    clf.fit(X_tr, y_tr, sample_weight=sample_w)\n",
        "    y_score = clf.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_pred = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te_true, bld_te_pred, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_adversarial(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, scope, seed=42, epochs=30):\n",
        "    bld_tr = to_bld_from_arrays(X_tr, y_tr, prot_tr, prot_name=prot_name)\n",
        "    bld_te = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    sess = tf.compat.v1.Session()\n",
        "    np.random.seed(seed)\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "    adv = AdversarialDebiasing(\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        scope_name=scope,\n",
        "        debias=True,\n",
        "        sess=sess,\n",
        "        num_epochs=30,            # keep lighter than 50\n",
        "        batch_size=256,\n",
        "        classifier_num_hidden_units=64\n",
        "    )\n",
        "    adv.fit(bld_tr)\n",
        "    bld_pred = adv.predict(bld_te)\n",
        "\n",
        "    y_pred = bld_pred.labels.ravel().astype(int)\n",
        "    y_score = bld_pred.scores.ravel()\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred, y_score)\n",
        "    fair = fairness_report(bld_te, bld_pred, prot_name)\n",
        "\n",
        "    sess.close()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    gc.collect()\n",
        "    return perf, fair\n",
        "\n",
        "def s5_run_roc_postproc(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    base = LogisticRegression(max_iter=300, random_state=seed)\n",
        "    base.fit(X_tr, y_tr)\n",
        "    y_score = base.predict_proba(X_te)[:, 1]\n",
        "    y_pred  = (y_score >= 0.5).astype(int)\n",
        "\n",
        "    bld_te_true   = to_bld_from_arrays(X_te, y_te, prot_te, prot_name=prot_name)\n",
        "    bld_te_scores = to_bld_from_arrays(X_te, y_pred, prot_te, prot_name=prot_name)\n",
        "    bld_te_scores.scores = y_score.reshape(-1, 1)\n",
        "\n",
        "    roc = RejectOptionClassification(\n",
        "        unprivileged_groups=[{prot_name: 1}],\n",
        "        privileged_groups=[{prot_name: 0}],\n",
        "        metric_name=\"Statistical parity difference\",\n",
        "        metric_lb=-0.02, metric_ub=0.02,\n",
        "        num_class_thresh=100, num_ROC_margin=50\n",
        "    )\n",
        "    roc = roc.fit(bld_te_true, bld_te_scores)\n",
        "    bld_post = roc.predict(bld_te_scores)\n",
        "\n",
        "    y_pred_post = bld_post.labels.ravel().astype(int)\n",
        "    y_score_post = getattr(bld_post, 'scores', None)\n",
        "    if y_score_post is None:\n",
        "        y_score_post = y_score\n",
        "\n",
        "    perf = compute_performance(y_te, y_pred_post, y_score_post)\n",
        "    fair = fairness_report(bld_te_true, bld_post, prot_name)\n",
        "    return perf, fair\n",
        "\n",
        "def run_once_for_attr(dataset_name, X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=42):\n",
        "    out = []\n",
        "    perf, fair = s5_run_baseline(X_tr, y_tr, X_te, y_te, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Baseline', **perf, **fair))\n",
        "\n",
        "    perf, fair = s5_run_reweighing(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Reweighing', **perf, **fair))\n",
        "\n",
        "    scope = f\"adv_{dataset_name}_{prot_name}_seed{seed}\"\n",
        "    perf, fair = s5_run_adversarial(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, scope=scope, seed=seed, epochs=30)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='Adversarial', **perf, **fair))\n",
        "\n",
        "    perf, fair = s5_run_roc_postproc(X_tr, y_tr, X_te, y_te, prot_tr, prot_te, prot_name, seed=seed)\n",
        "    out.append(dict(dataset=dataset_name, protected_attr=prot_name, method='ROC_post', **perf, **fair))\n",
        "    return out\n",
        "\n",
        "# Kaggle only repeated runs\n",
        "\n",
        "n_runs = 5\n",
        "all_rows = []\n",
        "\n",
        "for r in range(n_runs):\n",
        "    seed = 42 + r\n",
        "\n",
        "    # Kaggle - age_bin\n",
        "    all_rows += run_once_for_attr(\n",
        "        'Kaggle',\n",
        "        X_tr_kg_t, y_tr_kg, X_te_kg_t, y_te_kg,\n",
        "        p_tr_kg_age, p_te_kg_age,\n",
        "        'age_bin',\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "    # Kaggle - edu_bin\n",
        "    all_rows += run_once_for_attr(\n",
        "        'Kaggle',\n",
        "        X_tr_kg_t, y_tr_kg, X_te_kg_t, y_te_kg,\n",
        "        p_tr_kg_edu, p_te_kg_edu,\n",
        "        'edu_bin',\n",
        "        seed=seed\n",
        "    )\n",
        "\n",
        "res5_kaggle = pd.DataFrame(all_rows)\n",
        "print_block('STEP 5B — KAGGLE RAW (head)', res5_kaggle.head())\n",
        "print_block('KAGGLE Results shape', res5_kaggle.shape)\n",
        "\n",
        "summary5_kaggle = summarize_mean_std(res5_kaggle, group_cols=('dataset','protected_attr','method'))\n",
        "print_block('STEP 5B — KAGGLE MEAN ± STD', summary5_kaggle)\n",
        "\n",
        "metrics = ['accuracy', 'f1', 'auc', 'SPD', 'EOD', 'DI']\n",
        "methods_to_compare = ['Reweighing', 'Adversarial', 'ROC_post']\n",
        "\n",
        "pv_rows = []\n",
        "for (ds, attr), grp in res5_kaggle.groupby(['dataset','protected_attr']):\n",
        "    base = grp[grp['method'] == 'Baseline']\n",
        "    for m in methods_to_compare:\n",
        "        comp = grp[grp['method'] == m]\n",
        "        for metric in metrics:\n",
        "            base_vals = base[metric].values\n",
        "            comp_vals = comp[metric].values\n",
        "            if len(base_vals) == len(comp_vals) and len(base_vals) > 1:\n",
        "                pvals = paired_tests(base_vals, comp_vals)\n",
        "                pv_rows.append({\n",
        "                    'dataset': ds,\n",
        "                    'protected_attr': attr,\n",
        "                    'method_vs_baseline': m,\n",
        "                    'metric': metric,\n",
        "                    'ttest_p': pvals['ttest_p'],\n",
        "                    'wilcoxon_p': pvals['wilcoxon_p']\n",
        "                })\n",
        "\n",
        "pvals5_kaggle = pd.DataFrame(pv_rows)\n",
        "if not pvals5_kaggle.empty:\n",
        "    pvals5_kaggle['sig_ttest@0.05'] = pvals5_kaggle['ttest_p'] < 0.05\n",
        "    pvals5_kaggle['sig_wilcoxon@0.05'] = pvals5_kaggle['wilcoxon_p'] < 0.05\n",
        "\n",
        "print_block('STEP 5B — KAGGLE SIGNIFICANCE', pvals5_kaggle)\n",
        "\n",
        "# Save artifacts to disk\n",
        "res5_kaggle.to_csv('step5_kaggle_raw.csv', index=False)\n",
        "summary5_kaggle.to_csv('step5_kaggle_summary.csv', index=False)\n",
        "pvals5_kaggle.to_csv('step5_kaggle_pvals.csv', index=False)\n",
        "\n",
        "print('\\nSaved: step5_kaggle_raw.csv, step5_kaggle_summary.csv, step5_kaggle_pvals.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXg8kDK7LlKd",
        "outputId": "12264668-e6c5-4066-8fc1-1c6e7561e897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.896412; batch adversarial loss: 0.696458\n",
            "epoch 1; iter: 0; batch classifier loss: 0.843614; batch adversarial loss: 0.670863\n",
            "epoch 2; iter: 0; batch classifier loss: 0.864863; batch adversarial loss: 0.660115\n",
            "epoch 3; iter: 0; batch classifier loss: 0.810308; batch adversarial loss: 0.660333\n",
            "epoch 4; iter: 0; batch classifier loss: 0.758222; batch adversarial loss: 0.663698\n",
            "epoch 5; iter: 0; batch classifier loss: 0.724666; batch adversarial loss: 0.679846\n",
            "epoch 6; iter: 0; batch classifier loss: 0.697580; batch adversarial loss: 0.682563\n",
            "epoch 7; iter: 0; batch classifier loss: 0.710323; batch adversarial loss: 0.649437\n",
            "epoch 8; iter: 0; batch classifier loss: 0.662141; batch adversarial loss: 0.698299\n",
            "epoch 9; iter: 0; batch classifier loss: 0.646967; batch adversarial loss: 0.676430\n",
            "epoch 10; iter: 0; batch classifier loss: 0.629738; batch adversarial loss: 0.679103\n",
            "epoch 11; iter: 0; batch classifier loss: 0.611379; batch adversarial loss: 0.658841\n",
            "epoch 12; iter: 0; batch classifier loss: 0.594450; batch adversarial loss: 0.673015\n",
            "epoch 13; iter: 0; batch classifier loss: 0.559447; batch adversarial loss: 0.662134\n",
            "epoch 14; iter: 0; batch classifier loss: 0.537868; batch adversarial loss: 0.684550\n",
            "epoch 15; iter: 0; batch classifier loss: 0.547917; batch adversarial loss: 0.674745\n",
            "epoch 16; iter: 0; batch classifier loss: 0.545810; batch adversarial loss: 0.663069\n",
            "epoch 17; iter: 0; batch classifier loss: 0.501081; batch adversarial loss: 0.655717\n",
            "epoch 18; iter: 0; batch classifier loss: 0.506343; batch adversarial loss: 0.678527\n",
            "epoch 19; iter: 0; batch classifier loss: 0.522165; batch adversarial loss: 0.686467\n",
            "epoch 20; iter: 0; batch classifier loss: 0.510378; batch adversarial loss: 0.680959\n",
            "epoch 21; iter: 0; batch classifier loss: 0.470318; batch adversarial loss: 0.642509\n",
            "epoch 22; iter: 0; batch classifier loss: 0.496801; batch adversarial loss: 0.679424\n",
            "epoch 23; iter: 0; batch classifier loss: 0.467022; batch adversarial loss: 0.687800\n",
            "epoch 24; iter: 0; batch classifier loss: 0.490475; batch adversarial loss: 0.689605\n",
            "epoch 25; iter: 0; batch classifier loss: 0.478071; batch adversarial loss: 0.658493\n",
            "epoch 26; iter: 0; batch classifier loss: 0.455903; batch adversarial loss: 0.657332\n",
            "epoch 27; iter: 0; batch classifier loss: 0.458209; batch adversarial loss: 0.640404\n",
            "epoch 28; iter: 0; batch classifier loss: 0.388906; batch adversarial loss: 0.676220\n",
            "epoch 29; iter: 0; batch classifier loss: 0.426094; batch adversarial loss: 0.679032\n",
            "epoch 0; iter: 0; batch classifier loss: 0.911781; batch adversarial loss: 0.728136\n",
            "epoch 1; iter: 0; batch classifier loss: 0.860237; batch adversarial loss: 0.662151\n",
            "epoch 2; iter: 0; batch classifier loss: 0.877128; batch adversarial loss: 0.690151\n",
            "epoch 3; iter: 0; batch classifier loss: 0.823755; batch adversarial loss: 0.686436\n",
            "epoch 4; iter: 0; batch classifier loss: 0.772509; batch adversarial loss: 0.686628\n",
            "epoch 5; iter: 0; batch classifier loss: 0.737889; batch adversarial loss: 0.698064\n",
            "epoch 6; iter: 0; batch classifier loss: 0.712719; batch adversarial loss: 0.690722\n",
            "epoch 7; iter: 0; batch classifier loss: 0.710751; batch adversarial loss: 0.681683\n",
            "epoch 8; iter: 0; batch classifier loss: 0.668392; batch adversarial loss: 0.664589\n",
            "epoch 9; iter: 0; batch classifier loss: 0.657602; batch adversarial loss: 0.675009\n",
            "epoch 10; iter: 0; batch classifier loss: 0.639861; batch adversarial loss: 0.689810\n",
            "epoch 11; iter: 0; batch classifier loss: 0.628167; batch adversarial loss: 0.678102\n",
            "epoch 12; iter: 0; batch classifier loss: 0.615458; batch adversarial loss: 0.684575\n",
            "epoch 13; iter: 0; batch classifier loss: 0.567573; batch adversarial loss: 0.672528\n",
            "epoch 14; iter: 0; batch classifier loss: 0.547402; batch adversarial loss: 0.680038\n",
            "epoch 15; iter: 0; batch classifier loss: 0.568895; batch adversarial loss: 0.661264\n",
            "epoch 16; iter: 0; batch classifier loss: 0.576439; batch adversarial loss: 0.673576\n",
            "epoch 17; iter: 0; batch classifier loss: 0.547146; batch adversarial loss: 0.677464\n",
            "epoch 18; iter: 0; batch classifier loss: 0.530911; batch adversarial loss: 0.670964\n",
            "epoch 19; iter: 0; batch classifier loss: 0.540976; batch adversarial loss: 0.676902\n",
            "epoch 20; iter: 0; batch classifier loss: 0.534050; batch adversarial loss: 0.687045\n",
            "epoch 21; iter: 0; batch classifier loss: 0.498760; batch adversarial loss: 0.661569\n",
            "epoch 22; iter: 0; batch classifier loss: 0.499081; batch adversarial loss: 0.661041\n",
            "epoch 23; iter: 0; batch classifier loss: 0.501281; batch adversarial loss: 0.668400\n",
            "epoch 24; iter: 0; batch classifier loss: 0.504171; batch adversarial loss: 0.655189\n",
            "epoch 25; iter: 0; batch classifier loss: 0.493494; batch adversarial loss: 0.675798\n",
            "epoch 26; iter: 0; batch classifier loss: 0.468433; batch adversarial loss: 0.672440\n",
            "epoch 27; iter: 0; batch classifier loss: 0.486954; batch adversarial loss: 0.705339\n",
            "epoch 28; iter: 0; batch classifier loss: 0.400162; batch adversarial loss: 0.692650\n",
            "epoch 29; iter: 0; batch classifier loss: 0.452249; batch adversarial loss: 0.680814\n",
            "epoch 0; iter: 0; batch classifier loss: 0.807070; batch adversarial loss: 0.914877\n",
            "epoch 1; iter: 0; batch classifier loss: 0.772522; batch adversarial loss: 0.900514\n",
            "epoch 2; iter: 0; batch classifier loss: 0.744550; batch adversarial loss: 0.854141\n",
            "epoch 3; iter: 0; batch classifier loss: 0.721110; batch adversarial loss: 0.901132\n",
            "epoch 4; iter: 0; batch classifier loss: 0.703496; batch adversarial loss: 0.859420\n",
            "epoch 5; iter: 0; batch classifier loss: 0.691026; batch adversarial loss: 0.852216\n",
            "epoch 6; iter: 0; batch classifier loss: 0.660986; batch adversarial loss: 0.855670\n",
            "epoch 7; iter: 0; batch classifier loss: 0.677620; batch adversarial loss: 0.890954\n",
            "epoch 8; iter: 0; batch classifier loss: 0.685968; batch adversarial loss: 0.887479\n",
            "epoch 9; iter: 0; batch classifier loss: 0.622891; batch adversarial loss: 0.886124\n",
            "epoch 10; iter: 0; batch classifier loss: 0.645270; batch adversarial loss: 0.873973\n",
            "epoch 11; iter: 0; batch classifier loss: 0.623622; batch adversarial loss: 0.876020\n",
            "epoch 12; iter: 0; batch classifier loss: 0.629636; batch adversarial loss: 0.875259\n",
            "epoch 13; iter: 0; batch classifier loss: 0.611606; batch adversarial loss: 0.867224\n",
            "epoch 14; iter: 0; batch classifier loss: 0.604260; batch adversarial loss: 0.845979\n",
            "epoch 15; iter: 0; batch classifier loss: 0.572947; batch adversarial loss: 0.852830\n",
            "epoch 16; iter: 0; batch classifier loss: 0.603383; batch adversarial loss: 0.849111\n",
            "epoch 17; iter: 0; batch classifier loss: 0.631327; batch adversarial loss: 0.888759\n",
            "epoch 18; iter: 0; batch classifier loss: 0.637492; batch adversarial loss: 0.883125\n",
            "epoch 19; iter: 0; batch classifier loss: 0.550971; batch adversarial loss: 0.837735\n",
            "epoch 20; iter: 0; batch classifier loss: 0.615717; batch adversarial loss: 0.872788\n",
            "epoch 21; iter: 0; batch classifier loss: 0.632745; batch adversarial loss: 0.870289\n",
            "epoch 22; iter: 0; batch classifier loss: 0.651671; batch adversarial loss: 0.898911\n",
            "epoch 23; iter: 0; batch classifier loss: 0.630772; batch adversarial loss: 0.880848\n",
            "epoch 24; iter: 0; batch classifier loss: 0.690223; batch adversarial loss: 0.888369\n",
            "epoch 25; iter: 0; batch classifier loss: 0.619413; batch adversarial loss: 0.878175\n",
            "epoch 26; iter: 0; batch classifier loss: 0.619665; batch adversarial loss: 0.883974\n",
            "epoch 27; iter: 0; batch classifier loss: 0.634736; batch adversarial loss: 0.886988\n",
            "epoch 28; iter: 0; batch classifier loss: 0.649751; batch adversarial loss: 0.883625\n",
            "epoch 29; iter: 0; batch classifier loss: 0.655043; batch adversarial loss: 0.882108\n",
            "epoch 0; iter: 0; batch classifier loss: 0.803160; batch adversarial loss: 1.002452\n",
            "epoch 1; iter: 0; batch classifier loss: 0.785117; batch adversarial loss: 1.022534\n",
            "epoch 2; iter: 0; batch classifier loss: 0.779789; batch adversarial loss: 0.983483\n",
            "epoch 3; iter: 0; batch classifier loss: 0.771186; batch adversarial loss: 1.003064\n",
            "epoch 4; iter: 0; batch classifier loss: 0.780885; batch adversarial loss: 1.029139\n",
            "epoch 5; iter: 0; batch classifier loss: 0.789904; batch adversarial loss: 1.014889\n",
            "epoch 6; iter: 0; batch classifier loss: 0.775514; batch adversarial loss: 1.011888\n",
            "epoch 7; iter: 0; batch classifier loss: 0.809133; batch adversarial loss: 1.054406\n",
            "epoch 8; iter: 0; batch classifier loss: 0.806038; batch adversarial loss: 1.012419\n",
            "epoch 9; iter: 0; batch classifier loss: 0.758925; batch adversarial loss: 0.976755\n",
            "epoch 10; iter: 0; batch classifier loss: 0.785335; batch adversarial loss: 1.000177\n",
            "epoch 11; iter: 0; batch classifier loss: 0.791337; batch adversarial loss: 0.996368\n",
            "epoch 12; iter: 0; batch classifier loss: 0.836627; batch adversarial loss: 1.046466\n",
            "epoch 13; iter: 0; batch classifier loss: 0.821584; batch adversarial loss: 1.009839\n",
            "epoch 14; iter: 0; batch classifier loss: 0.842130; batch adversarial loss: 1.029965\n",
            "epoch 15; iter: 0; batch classifier loss: 0.780377; batch adversarial loss: 0.989188\n",
            "epoch 16; iter: 0; batch classifier loss: 0.829044; batch adversarial loss: 1.015608\n",
            "epoch 17; iter: 0; batch classifier loss: 0.872440; batch adversarial loss: 1.051476\n",
            "epoch 18; iter: 0; batch classifier loss: 0.820986; batch adversarial loss: 0.996574\n",
            "epoch 19; iter: 0; batch classifier loss: 0.811607; batch adversarial loss: 0.998055\n",
            "epoch 20; iter: 0; batch classifier loss: 0.813391; batch adversarial loss: 0.976077\n",
            "epoch 21; iter: 0; batch classifier loss: 0.846900; batch adversarial loss: 1.001741\n",
            "epoch 22; iter: 0; batch classifier loss: 0.870570; batch adversarial loss: 1.034817\n",
            "epoch 23; iter: 0; batch classifier loss: 0.861809; batch adversarial loss: 1.016223\n",
            "epoch 24; iter: 0; batch classifier loss: 0.936678; batch adversarial loss: 1.052582\n",
            "epoch 25; iter: 0; batch classifier loss: 0.884706; batch adversarial loss: 1.020881\n",
            "epoch 26; iter: 0; batch classifier loss: 0.889535; batch adversarial loss: 1.031053\n",
            "epoch 27; iter: 0; batch classifier loss: 0.919029; batch adversarial loss: 1.026519\n",
            "epoch 28; iter: 0; batch classifier loss: 0.899746; batch adversarial loss: 1.008097\n",
            "epoch 29; iter: 0; batch classifier loss: 0.875787; batch adversarial loss: 0.993851\n",
            "epoch 0; iter: 0; batch classifier loss: 0.781454; batch adversarial loss: 0.703429\n",
            "epoch 1; iter: 0; batch classifier loss: 0.751435; batch adversarial loss: 0.644773\n",
            "epoch 2; iter: 0; batch classifier loss: 0.732762; batch adversarial loss: 0.663151\n",
            "epoch 3; iter: 0; batch classifier loss: 0.707063; batch adversarial loss: 0.711145\n",
            "epoch 4; iter: 0; batch classifier loss: 0.680940; batch adversarial loss: 0.760987\n",
            "epoch 5; iter: 0; batch classifier loss: 0.653438; batch adversarial loss: 0.689753\n",
            "epoch 6; iter: 0; batch classifier loss: 0.639909; batch adversarial loss: 0.728709\n",
            "epoch 7; iter: 0; batch classifier loss: 0.614760; batch adversarial loss: 0.742845\n",
            "epoch 8; iter: 0; batch classifier loss: 0.594689; batch adversarial loss: 0.706716\n",
            "epoch 9; iter: 0; batch classifier loss: 0.591891; batch adversarial loss: 0.713475\n",
            "epoch 10; iter: 0; batch classifier loss: 0.563781; batch adversarial loss: 0.730257\n",
            "epoch 11; iter: 0; batch classifier loss: 0.550464; batch adversarial loss: 0.716165\n",
            "epoch 12; iter: 0; batch classifier loss: 0.537792; batch adversarial loss: 0.709303\n",
            "epoch 13; iter: 0; batch classifier loss: 0.530493; batch adversarial loss: 0.720129\n",
            "epoch 14; iter: 0; batch classifier loss: 0.490903; batch adversarial loss: 0.705514\n",
            "epoch 15; iter: 0; batch classifier loss: 0.495714; batch adversarial loss: 0.737682\n",
            "epoch 16; iter: 0; batch classifier loss: 0.496683; batch adversarial loss: 0.718117\n",
            "epoch 17; iter: 0; batch classifier loss: 0.497772; batch adversarial loss: 0.703663\n",
            "epoch 18; iter: 0; batch classifier loss: 0.457969; batch adversarial loss: 0.722267\n",
            "epoch 19; iter: 0; batch classifier loss: 0.465853; batch adversarial loss: 0.729309\n",
            "epoch 20; iter: 0; batch classifier loss: 0.488484; batch adversarial loss: 0.699549\n",
            "epoch 21; iter: 0; batch classifier loss: 0.446142; batch adversarial loss: 0.708422\n",
            "epoch 22; iter: 0; batch classifier loss: 0.432480; batch adversarial loss: 0.724659\n",
            "epoch 23; iter: 0; batch classifier loss: 0.436876; batch adversarial loss: 0.735029\n",
            "epoch 24; iter: 0; batch classifier loss: 0.437633; batch adversarial loss: 0.733926\n",
            "epoch 25; iter: 0; batch classifier loss: 0.428620; batch adversarial loss: 0.733540\n",
            "epoch 26; iter: 0; batch classifier loss: 0.423451; batch adversarial loss: 0.746126\n",
            "epoch 27; iter: 0; batch classifier loss: 0.366051; batch adversarial loss: 0.722882\n",
            "epoch 28; iter: 0; batch classifier loss: 0.412191; batch adversarial loss: 0.721984\n",
            "epoch 29; iter: 0; batch classifier loss: 0.434532; batch adversarial loss: 0.725284\n",
            "epoch 0; iter: 0; batch classifier loss: 0.799181; batch adversarial loss: 0.600584\n",
            "epoch 1; iter: 0; batch classifier loss: 0.756978; batch adversarial loss: 0.587214\n",
            "epoch 2; iter: 0; batch classifier loss: 0.727754; batch adversarial loss: 0.615283\n",
            "epoch 3; iter: 0; batch classifier loss: 0.701027; batch adversarial loss: 0.595192\n",
            "epoch 4; iter: 0; batch classifier loss: 0.671048; batch adversarial loss: 0.573358\n",
            "epoch 5; iter: 0; batch classifier loss: 0.646287; batch adversarial loss: 0.590214\n",
            "epoch 6; iter: 0; batch classifier loss: 0.632194; batch adversarial loss: 0.595046\n",
            "epoch 7; iter: 0; batch classifier loss: 0.611598; batch adversarial loss: 0.608756\n",
            "epoch 8; iter: 0; batch classifier loss: 0.581219; batch adversarial loss: 0.654745\n",
            "epoch 9; iter: 0; batch classifier loss: 0.589342; batch adversarial loss: 0.609740\n",
            "epoch 10; iter: 0; batch classifier loss: 0.557929; batch adversarial loss: 0.626972\n",
            "epoch 11; iter: 0; batch classifier loss: 0.546436; batch adversarial loss: 0.627943\n",
            "epoch 12; iter: 0; batch classifier loss: 0.536359; batch adversarial loss: 0.631946\n",
            "epoch 13; iter: 0; batch classifier loss: 0.541213; batch adversarial loss: 0.636002\n",
            "epoch 14; iter: 0; batch classifier loss: 0.504610; batch adversarial loss: 0.621626\n",
            "epoch 15; iter: 0; batch classifier loss: 0.485222; batch adversarial loss: 0.641974\n",
            "epoch 16; iter: 0; batch classifier loss: 0.518273; batch adversarial loss: 0.627563\n",
            "epoch 17; iter: 0; batch classifier loss: 0.509574; batch adversarial loss: 0.620217\n",
            "epoch 18; iter: 0; batch classifier loss: 0.466172; batch adversarial loss: 0.627790\n",
            "epoch 19; iter: 0; batch classifier loss: 0.467928; batch adversarial loss: 0.643134\n",
            "epoch 20; iter: 0; batch classifier loss: 0.498453; batch adversarial loss: 0.623592\n",
            "epoch 21; iter: 0; batch classifier loss: 0.470702; batch adversarial loss: 0.618857\n",
            "epoch 22; iter: 0; batch classifier loss: 0.439499; batch adversarial loss: 0.665643\n",
            "epoch 23; iter: 0; batch classifier loss: 0.437837; batch adversarial loss: 0.640473\n",
            "epoch 24; iter: 0; batch classifier loss: 0.439330; batch adversarial loss: 0.612491\n",
            "epoch 25; iter: 0; batch classifier loss: 0.411802; batch adversarial loss: 0.653010\n",
            "epoch 26; iter: 0; batch classifier loss: 0.418729; batch adversarial loss: 0.651517\n",
            "epoch 27; iter: 0; batch classifier loss: 0.356951; batch adversarial loss: 0.629078\n",
            "epoch 28; iter: 0; batch classifier loss: 0.413087; batch adversarial loss: 0.653993\n",
            "epoch 29; iter: 0; batch classifier loss: 0.430563; batch adversarial loss: 0.637428\n",
            "epoch 0; iter: 0; batch classifier loss: 0.729015; batch adversarial loss: 0.826503\n",
            "epoch 1; iter: 0; batch classifier loss: 0.683416; batch adversarial loss: 0.777304\n",
            "epoch 2; iter: 0; batch classifier loss: 0.687496; batch adversarial loss: 0.801055\n",
            "epoch 3; iter: 0; batch classifier loss: 0.682247; batch adversarial loss: 0.798714\n",
            "epoch 4; iter: 0; batch classifier loss: 0.675770; batch adversarial loss: 0.794305\n",
            "epoch 5; iter: 0; batch classifier loss: 0.640803; batch adversarial loss: 0.798721\n",
            "epoch 6; iter: 0; batch classifier loss: 0.646491; batch adversarial loss: 0.782571\n",
            "epoch 7; iter: 0; batch classifier loss: 0.623094; batch adversarial loss: 0.811262\n",
            "epoch 8; iter: 0; batch classifier loss: 0.626363; batch adversarial loss: 0.791337\n",
            "epoch 9; iter: 0; batch classifier loss: 0.618140; batch adversarial loss: 0.811532\n",
            "epoch 10; iter: 0; batch classifier loss: 0.637526; batch adversarial loss: 0.827417\n",
            "epoch 11; iter: 0; batch classifier loss: 0.587490; batch adversarial loss: 0.816411\n",
            "epoch 12; iter: 0; batch classifier loss: 0.561665; batch adversarial loss: 0.811968\n",
            "epoch 13; iter: 0; batch classifier loss: 0.581975; batch adversarial loss: 0.809281\n",
            "epoch 14; iter: 0; batch classifier loss: 0.589064; batch adversarial loss: 0.805678\n",
            "epoch 15; iter: 0; batch classifier loss: 0.593028; batch adversarial loss: 0.823806\n",
            "epoch 16; iter: 0; batch classifier loss: 0.550256; batch adversarial loss: 0.791062\n",
            "epoch 17; iter: 0; batch classifier loss: 0.582785; batch adversarial loss: 0.816427\n",
            "epoch 18; iter: 0; batch classifier loss: 0.581915; batch adversarial loss: 0.827457\n",
            "epoch 19; iter: 0; batch classifier loss: 0.552652; batch adversarial loss: 0.777931\n",
            "epoch 20; iter: 0; batch classifier loss: 0.611525; batch adversarial loss: 0.807638\n",
            "epoch 21; iter: 0; batch classifier loss: 0.611335; batch adversarial loss: 0.808792\n",
            "epoch 22; iter: 0; batch classifier loss: 0.564148; batch adversarial loss: 0.802974\n",
            "epoch 23; iter: 0; batch classifier loss: 0.555304; batch adversarial loss: 0.791180\n",
            "epoch 24; iter: 0; batch classifier loss: 0.551114; batch adversarial loss: 0.789911\n",
            "epoch 25; iter: 0; batch classifier loss: 0.596275; batch adversarial loss: 0.836432\n",
            "epoch 26; iter: 0; batch classifier loss: 0.528891; batch adversarial loss: 0.795060\n",
            "epoch 27; iter: 0; batch classifier loss: 0.608741; batch adversarial loss: 0.834636\n",
            "epoch 28; iter: 0; batch classifier loss: 0.582348; batch adversarial loss: 0.813351\n",
            "epoch 29; iter: 0; batch classifier loss: 0.600596; batch adversarial loss: 0.814859\n",
            "epoch 0; iter: 0; batch classifier loss: 0.744008; batch adversarial loss: 0.912383\n",
            "epoch 1; iter: 0; batch classifier loss: 0.723187; batch adversarial loss: 0.950107\n",
            "epoch 2; iter: 0; batch classifier loss: 0.731690; batch adversarial loss: 0.950650\n",
            "epoch 3; iter: 0; batch classifier loss: 0.727735; batch adversarial loss: 0.908589\n",
            "epoch 4; iter: 0; batch classifier loss: 0.750001; batch adversarial loss: 0.945774\n",
            "epoch 5; iter: 0; batch classifier loss: 0.708628; batch adversarial loss: 0.921591\n",
            "epoch 6; iter: 0; batch classifier loss: 0.737471; batch adversarial loss: 0.953922\n",
            "epoch 7; iter: 0; batch classifier loss: 0.700480; batch adversarial loss: 0.916408\n",
            "epoch 8; iter: 0; batch classifier loss: 0.757246; batch adversarial loss: 0.978733\n",
            "epoch 9; iter: 0; batch classifier loss: 0.732284; batch adversarial loss: 0.936495\n",
            "epoch 10; iter: 0; batch classifier loss: 0.752450; batch adversarial loss: 0.941141\n",
            "epoch 11; iter: 0; batch classifier loss: 0.740218; batch adversarial loss: 0.952275\n",
            "epoch 12; iter: 0; batch classifier loss: 0.745752; batch adversarial loss: 0.965575\n",
            "epoch 13; iter: 0; batch classifier loss: 0.752990; batch adversarial loss: 0.956631\n",
            "epoch 14; iter: 0; batch classifier loss: 0.802203; batch adversarial loss: 0.994664\n",
            "epoch 15; iter: 0; batch classifier loss: 0.791183; batch adversarial loss: 0.973685\n",
            "epoch 16; iter: 0; batch classifier loss: 0.812974; batch adversarial loss: 1.009244\n",
            "epoch 17; iter: 0; batch classifier loss: 0.781304; batch adversarial loss: 0.953905\n",
            "epoch 18; iter: 0; batch classifier loss: 0.768032; batch adversarial loss: 0.922676\n",
            "epoch 19; iter: 0; batch classifier loss: 0.770091; batch adversarial loss: 0.945839\n",
            "epoch 20; iter: 0; batch classifier loss: 0.823376; batch adversarial loss: 0.965485\n",
            "epoch 21; iter: 0; batch classifier loss: 0.764711; batch adversarial loss: 0.902757\n",
            "epoch 22; iter: 0; batch classifier loss: 0.792643; batch adversarial loss: 0.951405\n",
            "epoch 23; iter: 0; batch classifier loss: 0.813800; batch adversarial loss: 0.985431\n",
            "epoch 24; iter: 0; batch classifier loss: 0.788573; batch adversarial loss: 0.938214\n",
            "epoch 25; iter: 0; batch classifier loss: 0.828757; batch adversarial loss: 0.970154\n",
            "epoch 26; iter: 0; batch classifier loss: 0.775072; batch adversarial loss: 0.948851\n",
            "epoch 27; iter: 0; batch classifier loss: 0.807096; batch adversarial loss: 0.941273\n",
            "epoch 28; iter: 0; batch classifier loss: 0.795780; batch adversarial loss: 0.939068\n",
            "epoch 29; iter: 0; batch classifier loss: 0.827335; batch adversarial loss: 0.937779\n",
            "epoch 0; iter: 0; batch classifier loss: 0.815442; batch adversarial loss: 0.651595\n",
            "epoch 1; iter: 0; batch classifier loss: 0.797036; batch adversarial loss: 0.662879\n",
            "epoch 2; iter: 0; batch classifier loss: 0.771161; batch adversarial loss: 0.664365\n",
            "epoch 3; iter: 0; batch classifier loss: 0.689172; batch adversarial loss: 0.655237\n",
            "epoch 4; iter: 0; batch classifier loss: 0.694728; batch adversarial loss: 0.651735\n",
            "epoch 5; iter: 0; batch classifier loss: 0.680445; batch adversarial loss: 0.660384\n",
            "epoch 6; iter: 0; batch classifier loss: 0.650502; batch adversarial loss: 0.678006\n",
            "epoch 7; iter: 0; batch classifier loss: 0.611741; batch adversarial loss: 0.651725\n",
            "epoch 8; iter: 0; batch classifier loss: 0.612820; batch adversarial loss: 0.652564\n",
            "epoch 9; iter: 0; batch classifier loss: 0.563913; batch adversarial loss: 0.656693\n",
            "epoch 10; iter: 0; batch classifier loss: 0.576286; batch adversarial loss: 0.653911\n",
            "epoch 11; iter: 0; batch classifier loss: 0.533924; batch adversarial loss: 0.676792\n",
            "epoch 12; iter: 0; batch classifier loss: 0.531118; batch adversarial loss: 0.662516\n",
            "epoch 13; iter: 0; batch classifier loss: 0.507942; batch adversarial loss: 0.666859\n",
            "epoch 14; iter: 0; batch classifier loss: 0.518838; batch adversarial loss: 0.656337\n",
            "epoch 15; iter: 0; batch classifier loss: 0.508482; batch adversarial loss: 0.669414\n",
            "epoch 16; iter: 0; batch classifier loss: 0.467669; batch adversarial loss: 0.666058\n",
            "epoch 17; iter: 0; batch classifier loss: 0.477046; batch adversarial loss: 0.672533\n",
            "epoch 18; iter: 0; batch classifier loss: 0.479416; batch adversarial loss: 0.653721\n",
            "epoch 19; iter: 0; batch classifier loss: 0.458800; batch adversarial loss: 0.660909\n",
            "epoch 20; iter: 0; batch classifier loss: 0.466201; batch adversarial loss: 0.671408\n",
            "epoch 21; iter: 0; batch classifier loss: 0.468115; batch adversarial loss: 0.672625\n",
            "epoch 22; iter: 0; batch classifier loss: 0.452805; batch adversarial loss: 0.667534\n",
            "epoch 23; iter: 0; batch classifier loss: 0.458404; batch adversarial loss: 0.679331\n",
            "epoch 24; iter: 0; batch classifier loss: 0.464087; batch adversarial loss: 0.658747\n",
            "epoch 25; iter: 0; batch classifier loss: 0.457521; batch adversarial loss: 0.653120\n",
            "epoch 26; iter: 0; batch classifier loss: 0.456141; batch adversarial loss: 0.671165\n",
            "epoch 27; iter: 0; batch classifier loss: 0.434955; batch adversarial loss: 0.667366\n",
            "epoch 28; iter: 0; batch classifier loss: 0.457777; batch adversarial loss: 0.675054\n",
            "epoch 29; iter: 0; batch classifier loss: 0.402609; batch adversarial loss: 0.654540\n",
            "epoch 0; iter: 0; batch classifier loss: 0.821598; batch adversarial loss: 0.616664\n",
            "epoch 1; iter: 0; batch classifier loss: 0.808052; batch adversarial loss: 0.623391\n",
            "epoch 2; iter: 0; batch classifier loss: 0.787638; batch adversarial loss: 0.620962\n",
            "epoch 3; iter: 0; batch classifier loss: 0.710265; batch adversarial loss: 0.628295\n",
            "epoch 4; iter: 0; batch classifier loss: 0.714202; batch adversarial loss: 0.622552\n",
            "epoch 5; iter: 0; batch classifier loss: 0.712213; batch adversarial loss: 0.605703\n",
            "epoch 6; iter: 0; batch classifier loss: 0.669341; batch adversarial loss: 0.641605\n",
            "epoch 7; iter: 0; batch classifier loss: 0.645699; batch adversarial loss: 0.633108\n",
            "epoch 8; iter: 0; batch classifier loss: 0.662083; batch adversarial loss: 0.620504\n",
            "epoch 9; iter: 0; batch classifier loss: 0.607651; batch adversarial loss: 0.632386\n",
            "epoch 10; iter: 0; batch classifier loss: 0.614920; batch adversarial loss: 0.630103\n",
            "epoch 11; iter: 0; batch classifier loss: 0.595719; batch adversarial loss: 0.627909\n",
            "epoch 12; iter: 0; batch classifier loss: 0.606762; batch adversarial loss: 0.611393\n",
            "epoch 13; iter: 0; batch classifier loss: 0.571553; batch adversarial loss: 0.620447\n",
            "epoch 14; iter: 0; batch classifier loss: 0.588447; batch adversarial loss: 0.623456\n",
            "epoch 15; iter: 0; batch classifier loss: 0.562470; batch adversarial loss: 0.615981\n",
            "epoch 16; iter: 0; batch classifier loss: 0.561817; batch adversarial loss: 0.598978\n",
            "epoch 17; iter: 0; batch classifier loss: 0.551192; batch adversarial loss: 0.611612\n",
            "epoch 18; iter: 0; batch classifier loss: 0.542964; batch adversarial loss: 0.630333\n",
            "epoch 19; iter: 0; batch classifier loss: 0.544534; batch adversarial loss: 0.618230\n",
            "epoch 20; iter: 0; batch classifier loss: 0.526364; batch adversarial loss: 0.632041\n",
            "epoch 21; iter: 0; batch classifier loss: 0.536725; batch adversarial loss: 0.607237\n",
            "epoch 22; iter: 0; batch classifier loss: 0.533363; batch adversarial loss: 0.614327\n",
            "epoch 23; iter: 0; batch classifier loss: 0.516205; batch adversarial loss: 0.609757\n",
            "epoch 24; iter: 0; batch classifier loss: 0.530279; batch adversarial loss: 0.635809\n",
            "epoch 25; iter: 0; batch classifier loss: 0.544227; batch adversarial loss: 0.627475\n",
            "epoch 26; iter: 0; batch classifier loss: 0.513942; batch adversarial loss: 0.624257\n",
            "epoch 27; iter: 0; batch classifier loss: 0.491680; batch adversarial loss: 0.618151\n",
            "epoch 28; iter: 0; batch classifier loss: 0.541666; batch adversarial loss: 0.633088\n",
            "epoch 29; iter: 0; batch classifier loss: 0.500488; batch adversarial loss: 0.609280\n",
            "\n",
            "====================================================================================================\n",
            "STEP 5B — KAGGLE RAW (head)\n",
            "====================================================================================================\n",
            "  dataset protected_attr       method  accuracy        f1       auc       SPD  \\\n",
            "0  Kaggle        age_bin     Baseline  0.856667  0.751445  0.891123  0.006030   \n",
            "1  Kaggle        age_bin   Reweighing  0.853333  0.747126  0.891642  0.011006   \n",
            "2  Kaggle        age_bin  Adversarial  0.840000  0.703704  0.865150  0.056837   \n",
            "3  Kaggle        age_bin     ROC_post  0.846667  0.757895  0.891123  0.015227   \n",
            "4  Kaggle        edu_bin     Baseline  0.856667  0.751445  0.891123 -0.264409   \n",
            "\n",
            "        EOD        DI  \n",
            "0 -0.050794  1.022962  \n",
            "1 -0.050794  1.041906  \n",
            "2  0.019048  1.296151  \n",
            "3  0.011111  1.048628  \n",
            "4 -0.161874  0.400673  \n",
            "\n",
            "====================================================================================================\n",
            "KAGGLE Results shape\n",
            "====================================================================================================\n",
            "(40, 9)\n",
            "\n",
            "====================================================================================================\n",
            "STEP 5B — KAGGLE MEAN ± STD\n",
            "====================================================================================================\n",
            "  dataset protected_attr       method  accuracy_mean  accuracy_std   f1_mean  \\\n",
            "0  Kaggle        age_bin  Adversarial       0.750667      0.101253  0.645299   \n",
            "1  Kaggle        age_bin     Baseline       0.856667      0.000000  0.751445   \n",
            "2  Kaggle        age_bin     ROC_post       0.846667      0.000000  0.757895   \n",
            "3  Kaggle        age_bin   Reweighing       0.853333      0.000000  0.747126   \n",
            "4  Kaggle        edu_bin  Adversarial       0.658667      0.209186  0.575989   \n",
            "5  Kaggle        edu_bin     Baseline       0.856667      0.000000  0.751445   \n",
            "6  Kaggle        edu_bin     ROC_post       0.820000      0.000000  0.727273   \n",
            "7  Kaggle        edu_bin   Reweighing       0.866667      0.000000  0.761905   \n",
            "\n",
            "     f1_std  auc_mean   auc_std  SPD_mean   SPD_std  EOD_mean   EOD_std  \\\n",
            "0  0.055060  0.836196  0.037194  0.192341  0.319975  0.073651  0.251332   \n",
            "1  0.000000  0.891123  0.000000  0.006030  0.000000 -0.050794  0.000000   \n",
            "2  0.000000  0.891123  0.000000  0.015227  0.000000  0.011111  0.000000   \n",
            "3  0.000000  0.891642  0.000000  0.011006  0.000000 -0.050794  0.000000   \n",
            "4  0.098883  0.780614  0.106139  0.198396  0.394797  0.158163  0.227312   \n",
            "5  0.000000  0.891123  0.000000 -0.264409  0.000000 -0.161874  0.000000   \n",
            "6  0.000000  0.891123  0.000000 -0.019311  0.000000  0.083488  0.000000   \n",
            "7  0.000000  0.887486  0.000000 -0.141117  0.000000 -0.012059  0.000000   \n",
            "\n",
            "    DI_mean    DI_std  runs  \n",
            "0  1.916704  1.350291     5  \n",
            "1  1.022962  0.000000     5  \n",
            "2  1.048628  0.000000     5  \n",
            "3  1.041906  0.000000     5  \n",
            "4  1.571855  1.227738     5  \n",
            "5  0.400673  0.000000     5  \n",
            "6  0.946765  0.000000     5  \n",
            "7  0.588745  0.000000     5  \n",
            "\n",
            "====================================================================================================\n",
            "STEP 5B — KAGGLE SIGNIFICANCE\n",
            "====================================================================================================\n",
            "   dataset protected_attr method_vs_baseline    metric       ttest_p  \\\n",
            "0   Kaggle        age_bin         Reweighing  accuracy  0.000000e+00   \n",
            "1   Kaggle        age_bin         Reweighing        f1  0.000000e+00   \n",
            "2   Kaggle        age_bin         Reweighing       auc  0.000000e+00   \n",
            "3   Kaggle        age_bin         Reweighing       SPD  0.000000e+00   \n",
            "4   Kaggle        age_bin         Reweighing       EOD           NaN   \n",
            "5   Kaggle        age_bin         Reweighing        DI  0.000000e+00   \n",
            "6   Kaggle        age_bin        Adversarial  accuracy  7.930072e-02   \n",
            "7   Kaggle        age_bin        Adversarial        f1  1.253829e-02   \n",
            "8   Kaggle        age_bin        Adversarial       auc  2.987413e-02   \n",
            "9   Kaggle        age_bin        Adversarial       SPD  2.628343e-01   \n",
            "10  Kaggle        age_bin        Adversarial       EOD  3.303184e-01   \n",
            "11  Kaggle        age_bin        Adversarial        DI  2.129675e-01   \n",
            "12  Kaggle        age_bin           ROC_post  accuracy  0.000000e+00   \n",
            "13  Kaggle        age_bin           ROC_post        f1  0.000000e+00   \n",
            "14  Kaggle        age_bin           ROC_post       auc           NaN   \n",
            "15  Kaggle        age_bin           ROC_post       SPD  0.000000e+00   \n",
            "16  Kaggle        age_bin           ROC_post       EOD  0.000000e+00   \n",
            "17  Kaggle        age_bin           ROC_post        DI  0.000000e+00   \n",
            "18  Kaggle        edu_bin         Reweighing  accuracy  0.000000e+00   \n",
            "19  Kaggle        edu_bin         Reweighing        f1  0.000000e+00   \n",
            "20  Kaggle        edu_bin         Reweighing       auc  0.000000e+00   \n",
            "21  Kaggle        edu_bin         Reweighing       SPD  0.000000e+00   \n",
            "22  Kaggle        edu_bin         Reweighing       EOD  0.000000e+00   \n",
            "23  Kaggle        edu_bin         Reweighing        DI  0.000000e+00   \n",
            "24  Kaggle        edu_bin        Adversarial  accuracy  1.017431e-01   \n",
            "25  Kaggle        edu_bin        Adversarial        f1  1.657135e-02   \n",
            "26  Kaggle        edu_bin        Adversarial       auc  8.041743e-02   \n",
            "27  Kaggle        edu_bin        Adversarial       SPD  5.872239e-02   \n",
            "28  Kaggle        edu_bin        Adversarial       EOD  3.457387e-02   \n",
            "29  Kaggle        edu_bin        Adversarial        DI  9.986347e-02   \n",
            "30  Kaggle        edu_bin           ROC_post  accuracy  0.000000e+00   \n",
            "31  Kaggle        edu_bin           ROC_post        f1  0.000000e+00   \n",
            "32  Kaggle        edu_bin           ROC_post       auc           NaN   \n",
            "33  Kaggle        edu_bin           ROC_post       SPD  0.000000e+00   \n",
            "34  Kaggle        edu_bin           ROC_post       EOD  6.140512e-65   \n",
            "35  Kaggle        edu_bin           ROC_post        DI  0.000000e+00   \n",
            "\n",
            "    wilcoxon_p  sig_ttest@0.05  sig_wilcoxon@0.05  \n",
            "0       0.0625            True              False  \n",
            "1       0.0625            True              False  \n",
            "2       0.0625            True              False  \n",
            "3       0.0625            True              False  \n",
            "4          NaN           False              False  \n",
            "5       0.0625            True              False  \n",
            "6       0.0625           False              False  \n",
            "7       0.0625            True              False  \n",
            "8       0.0625            True              False  \n",
            "9       0.3125           False              False  \n",
            "10      0.3125           False              False  \n",
            "11      0.3125           False              False  \n",
            "12      0.0625            True              False  \n",
            "13      0.0625            True              False  \n",
            "14         NaN           False              False  \n",
            "15      0.0625            True              False  \n",
            "16      0.0625            True              False  \n",
            "17      0.0625            True              False  \n",
            "18      0.0625            True              False  \n",
            "19      0.0625            True              False  \n",
            "20      0.0625            True              False  \n",
            "21      0.0625            True              False  \n",
            "22      0.0625            True              False  \n",
            "23      0.0625            True              False  \n",
            "24      0.0625           False              False  \n",
            "25      0.0625            True              False  \n",
            "26      0.0625           False              False  \n",
            "27      0.0625           False              False  \n",
            "28      0.0625            True              False  \n",
            "29      0.0625           False              False  \n",
            "30      0.0625            True              False  \n",
            "31      0.0625            True              False  \n",
            "32         NaN           False              False  \n",
            "33      0.0625            True              False  \n",
            "34      0.0625            True              False  \n",
            "35      0.0625            True              False  \n",
            "\n",
            "Saved: step5_kaggle_raw.csv, step5_kaggle_summary.csv, step5_kaggle_pvals.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh *.csv\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"step5_kaggle_raw.csv\")\n",
        "files.download(\"step5_kaggle_summary.csv\")\n",
        "files.download(\"step5_kaggle_pvals.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Kq7_MarqNdZM",
        "outputId": "c805c375-c58b-4dfd-c266-741e656f1154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 1.7M Aug 10 18:14 'adult_test (1).csv'\n",
            "-rw-r--r-- 1 root root 1.7M Aug 10 17:15  adult_test.csv\n",
            "-rw-r--r-- 1 root root 3.4M Aug 10 18:14 'adult_train (1).csv'\n",
            "-rw-r--r-- 1 root root 3.4M Aug 10 17:15  adult_train.csv\n",
            "-rw-r--r-- 1 root root  63K Aug 10 18:14 'recruitment_data (1).csv'\n",
            "-rw-r--r-- 1 root root  63K Aug 10 17:15  recruitment_data.csv\n",
            "-rw-r--r-- 1 root root 2.1K Aug 10 18:08  step5_adult_pvals.csv\n",
            "-rw-r--r-- 1 root root 5.6K Aug 10 18:08  step5_adult_raw.csv\n",
            "-rw-r--r-- 1 root root 1.7K Aug 10 18:08  step5_adult_summary.csv\n",
            "-rw-r--r-- 1 root root 2.2K Aug 10 18:18  step5_kaggle_pvals.csv\n",
            "-rw-r--r-- 1 root root 5.6K Aug 10 18:18  step5_kaggle_raw.csv\n",
            "-rw-r--r-- 1 root root 1.7K Aug 10 18:18  step5_kaggle_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_84059c84-8f58-44b0-8bdb-fff75c6c9040\", \"step5_kaggle_raw.csv\", 5650)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1e09e5e-31a7-4772-92cc-04ffba7f7f49\", \"step5_kaggle_summary.csv\", 1663)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d633afd8-7a3f-4879-baaa-e722f743737f\", \"step5_kaggle_pvals.csv\", 2173)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results Visualization"
      ],
      "metadata": {
        "id": "5uqgzPsIH75E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouped Histograms (Performance & Fairness)"
      ],
      "metadata": {
        "id": "VhcPDCurIU-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "adult_perf = {\"Accuracy\": 0.853, \"F1\": 0.658, \"AUC\": 0.905}\n",
        "kaggle_perf = {\"Accuracy\": 0.857, \"F1\": 0.751, \"AUC\": 0.891}\n",
        "\n",
        "\n",
        "adult_age = {\"SPD\": -0.186, \"EOD\": -0.129, \"DI\": 0.376}\n",
        "kaggle_age = {\"SPD\":  0.006, \"EOD\": -0.051, \"DI\": 1.023}\n",
        "\n",
        "\n",
        "adult_edu = {\"SPD\": -0.434, \"EOD\": -0.479, \"DI\": 0.165}\n",
        "kaggle_edu = {\"SPD\": -0.264, \"EOD\": -0.162, \"DI\": 0.401}\n",
        "\n",
        "\n",
        "plt.rcParams.update({\"figure.dpi\": 160})\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "metrics_perf = list(adult_perf.keys())\n",
        "x = np.arange(len(metrics_perf))\n",
        "w = 0.35\n",
        "\n",
        "adult_vals = [adult_perf[m] for m in metrics_perf]\n",
        "kaggle_vals = [kaggle_perf[m] for m in metrics_perf]\n",
        "\n",
        "b1 = ax1.bar(x - w/2, adult_vals, width=w, label=\"Adult\")\n",
        "b2 = ax1.bar(x + w/2, kaggle_vals, width=w, label=\"Kaggle\")\n",
        "\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(metrics_perf)\n",
        "ax1.set_ylim(0, 1.05)\n",
        "ax1.set_ylabel(\"Score\")\n",
        "ax1.set_title(\"Baseline Performance (no debiasing)\")\n",
        "ax1.legend()\n",
        "\n",
        "\n",
        "def annotate_bars(ax, bars, fmt=\"{:.3f}\"):\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.annotate(fmt.format(h),\n",
        "                    xy=(bar.get_x() + bar.get_width()/2, h),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\",\n",
        "                    ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "\n",
        "annotate_bars(ax1, b1)\n",
        "annotate_bars(ax1, b2)\n",
        "\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "fair_metrics = [\"SPD\", \"EOD\", \"DI\"]\n",
        "\n",
        "\n",
        "cats = [f\"{m}(Age)\" for m in fair_metrics] + [f\"{m}(Edu)\" for m in fair_metrics]\n",
        "x2 = np.arange(len(cats))\n",
        "w2 = 0.35\n",
        "\n",
        "adult_vals2 = [adult_age[m] for m in fair_metrics] + [adult_edu[m] for m in fair_metrics]\n",
        "kaggle_vals2 = [kaggle_age[m] for m in fair_metrics] + [kaggle_edu[m] for m in fair_metrics]\n",
        "\n",
        "b3 = ax2.bar(x2 - w2/2, adult_vals2, width=w2, label=\"Adult\")\n",
        "b4 = ax2.bar(x2 + w2/2, kaggle_vals2, width=w2, label=\"Kaggle\")\n",
        "\n",
        "ax2.set_xticks(x2)\n",
        "ax2.set_xticklabels(cats, rotation=20)\n",
        "ax2.axhline(0, linestyle=\"--\", linewidth=1)\n",
        "ax2.set_ylabel(\"Value\")\n",
        "ax2.set_title(\"Baseline Fairness Metrics by Attribute\")\n",
        "ax2.legend()\n",
        "\n",
        "annotate_bars(ax2, b3)\n",
        "annotate_bars(ax2, b4)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"baseline_bars.png\", bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved: baseline_bars.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7gpTUiHIFM1",
        "outputId": "cc6971f9-bc68-4c44-bb0d-d33814d2ff4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: baseline_bars.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\": 160,\n",
        "    \"axes.unicode_minus\": False\n",
        "})\n",
        "\n",
        "baseline_perf = {\n",
        "    \"Adult\":   {\"Accuracy\": 0.853, \"F1\": 0.658, \"AUC\": 0.905},\n",
        "    \"Kaggle\":  {\"Accuracy\": 0.857, \"F1\": 0.751, \"AUC\": 0.891},\n",
        "}\n",
        "\n",
        "baseline_fair = {\n",
        "    (\"Adult\",  \"age\"): {\"SPD\": -0.186, \"EOD\": -0.129, \"DI\": 0.376},\n",
        "    (\"Adult\",  \"edu\"): {\"SPD\": -0.434, \"EOD\": -0.479, \"DI\": 0.165},\n",
        "    (\"Kaggle\", \"age\"): {\"SPD\":  0.006, \"EOD\": -0.051, \"DI\": 1.023},\n",
        "    (\"Kaggle\", \"edu\"): {\"SPD\": -0.264, \"EOD\": -0.162, \"DI\": 0.401},\n",
        "}\n",
        "\n",
        "methods = [\"Baseline\", \"Reweighing\", \"Adversarial\", \"ROC_post\"]\n",
        "\n",
        "perf = {\n",
        "    (\"Adult\",  \"age\"): {\n",
        "        \"Baseline\":   baseline_perf[\"Adult\"],\n",
        "        \"Reweighing\": {\"Accuracy\": 0.850772, \"F1\": 0.646459, \"AUC\": 0.899566},\n",
        "        \"Adversarial\":{\"Accuracy\": 0.848988, \"F1\": 0.641134, \"AUC\": 0.903116},\n",
        "        \"ROC_post\":   {\"Accuracy\": 0.777573, \"F1\": 0.635851, \"AUC\": 0.905339},\n",
        "    },\n",
        "    (\"Adult\",  \"edu\"): {\n",
        "        \"Baseline\":   baseline_perf[\"Adult\"],\n",
        "        \"Reweighing\": {\"Accuracy\": 0.831088, \"F1\": 0.596651, \"AUC\": 0.884159},\n",
        "        \"Adversarial\":{\"Accuracy\": 0.841238, \"F1\": 0.626537, \"AUC\": 0.900191},\n",
        "        \"ROC_post\":   {\"Accuracy\": 0.764286, \"F1\": 0.611043, \"AUC\": 0.905339},\n",
        "    },\n",
        "    (\"Kaggle\", \"age\"): {\n",
        "        \"Baseline\":   baseline_perf[\"Kaggle\"],\n",
        "        \"Reweighing\": {\"Accuracy\": 0.853333, \"F1\": 0.747126, \"AUC\": 0.891642},\n",
        "        \"Adversarial\":{\"Accuracy\": 0.846667, \"F1\": 0.722892, \"AUC\": 0.884525},\n",
        "        \"ROC_post\":   {\"Accuracy\": 0.846667, \"F1\": 0.757895, \"AUC\": 0.891123},\n",
        "    },\n",
        "    (\"Kaggle\", \"edu\"): {\n",
        "        \"Baseline\":   baseline_perf[\"Kaggle\"],\n",
        "        \"Reweighing\": {\"Accuracy\": 0.866667, \"F1\": 0.761905, \"AUC\": 0.887486},\n",
        "        \"Adversarial\":{\"Accuracy\": 0.860000, \"F1\": 0.740741, \"AUC\": 0.889201},\n",
        "        \"ROC_post\":   {\"Accuracy\": 0.820000, \"F1\": 0.727273, \"AUC\": 0.891123},\n",
        "    },\n",
        "}\n",
        "\n",
        "fair = {\n",
        "    (\"Adult\",  \"age\"): {\n",
        "        \"Baseline\":   baseline_fair[(\"Adult\",\"age\")],\n",
        "        \"Reweighing\": {\"SPD\": -0.114940, \"EOD\": -0.000812, \"DI\": 0.540433},\n",
        "        \"Adversarial\":{\"SPD\": -0.066077, \"EOD\":  0.110919, \"DI\": 0.701633},\n",
        "        \"ROC_post\":   {\"SPD\": -0.018674, \"EOD\":  0.176346, \"DI\": 0.951488},\n",
        "    },\n",
        "    (\"Adult\",  \"edu\"): {\n",
        "        \"Baseline\":   baseline_fair[(\"Adult\",\"edu\")],\n",
        "        \"Reweighing\": {\"SPD\": -0.125792, \"EOD\":  0.025151, \"DI\": 0.545889},\n",
        "        \"Adversarial\":{\"SPD\": -0.186249, \"EOD\": -0.057537, \"DI\": 0.433532},\n",
        "        \"ROC_post\":   {\"SPD\": -0.019757, \"EOD\":  0.227597, \"DI\": 0.948621},\n",
        "    },\n",
        "    (\"Kaggle\", \"age\"): {\n",
        "        \"Baseline\":   baseline_fair[(\"Kaggle\",\"age\")],\n",
        "        \"Reweighing\": {\"SPD\":  0.011006, \"EOD\": -0.050794, \"DI\": 1.041906},\n",
        "        \"Adversarial\":{\"SPD\":  0.061661, \"EOD\":  0.017460, \"DI\": 1.305224},\n",
        "        \"ROC_post\":   {\"SPD\":  0.015227, \"EOD\":  0.011111, \"DI\": 1.048628},\n",
        "    },\n",
        "    (\"Kaggle\", \"edu\"): {\n",
        "        \"Baseline\":   baseline_fair[(\"Kaggle\",\"edu\")],\n",
        "        \"Reweighing\": {\"SPD\": -0.141117, \"EOD\": -0.012059, \"DI\": 0.588745},\n",
        "        \"Adversarial\":{\"SPD\": -0.126857, \"EOD\":  0.026438, \"DI\": 0.595644},\n",
        "        \"ROC_post\":   {\"SPD\": -0.019311, \"EOD\":  0.083488, \"DI\": 0.946765},\n",
        "    },\n",
        "}\n",
        "\n",
        "def ensure_dir(path=\"figs\"):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    return path\n",
        "\n",
        "def annotate_bars(ax, bars, fmt=\"{:.3f}\"):\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.annotate(fmt.format(h),\n",
        "                    xy=(bar.get_x() + bar.get_width()/2, h),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\",\n",
        "                    ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "\n",
        "def plot_grouped_bars(metric_names, data_by_method, title, ylabel, save_path, ylim=None, rotate=0):\n",
        "    x = np.arange(len(metric_names))\n",
        "    group_w = 0.85\n",
        "    n = len(methods)\n",
        "    bar_w = group_w / n\n",
        "    offset = -(group_w - bar_w)/2\n",
        "    fig = plt.figure(figsize=(6.8, 4.5))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    for i, m in enumerate(methods):\n",
        "        vals = [data_by_method[m][mn] for mn in metric_names]\n",
        "        b = ax.bar(x + offset + i*bar_w, vals, width=bar_w, label=m)\n",
        "        annotate_bars(ax, b)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metric_names, rotation=rotate)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_title(title, pad=10)\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(*ylim)\n",
        "    ax.axhline(0, linestyle=\"--\", linewidth=1)\n",
        "    ax.legend(ncol=2, fontsize=9, frameon=True)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(save_path, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "\n",
        "outdir = ensure_dir(\"figs\")\n",
        "perf_metrics = [\"Accuracy\", \"F1\", \"AUC\"]\n",
        "fair_metrics = [\"SPD\", \"EOD\", \"DI\"]\n",
        "perf_ylim = (0.0, 1.05)\n",
        "fair_ylim = (-0.6, 1.4)\n",
        "labels_map = {\"age\": \"Binned Age\", \"edu\": \"Binned Education\"}\n",
        "\n",
        "for ds in [\"Adult\", \"Kaggle\"]:\n",
        "    for attr in [\"age\", \"edu\"]:\n",
        "        title_p = f\"{ds} – {labels_map[attr]}: Performance comparison (Accuracy / F1 / AUC)\"\n",
        "        file_p  = os.path.join(outdir, f\"fig4_3_performance_{ds.lower()}_{attr}.png\")\n",
        "        plot_grouped_bars(perf_metrics, perf[(ds, attr)], title_p, ylabel=\"Score\", save_path=file_p, ylim=perf_ylim, rotate=0)\n",
        "        title_f = f\"{ds} – {labels_map[attr]}: Fairness comparison (SPD / EOD / DI)\"\n",
        "        file_f  = os.path.join(outdir, f\"fig4_3_fairness_{ds.lower()}_{attr}.png\")\n",
        "        plot_grouped_bars(fair_metrics, fair[(ds, attr)], title_f, ylabel=\"Value\", save_path=file_f, ylim=fair_ylim, rotate=0)\n",
        "\n",
        "print(\"All figures saved to:\", outdir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E20-YrR6ITtY",
        "outputId": "ca25621f-502d-4303-eff5-90aa66291f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All figures saved to: figs\n"
          ]
        }
      ]
    }
  ]
}